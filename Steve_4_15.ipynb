{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "Table of Contents\n",
        "1. Drive Mount\n",
        "2. List of files\n",
        "3. Test Code & Shape of Datasets\n",
        "4. Single XGBoost model + 23 Features (0.1317)\n",
        "5. Multiple Algorithms (RF, GB, XGBoost)\n",
        "6. (RF, GB, XGBoost) w/ HT & AFE\n",
        "7. Train separate models for different data segments\n",
        "8. Advanced Stacking Ensemble + 38 Features (0.1112)\n",
        "\n",
        "Conclusion : XGBoost was Best Algorithm (You found it)\n",
        "You had to focus more on other parameters than n_estimators"
      ],
      "metadata": {
        "id": "wVYbAo8Rt5ya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6UduFwLtpJx",
        "outputId": "6b7b7a52-8241-4b3f-f928-fc43c31c9b0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# list top-level of your MyDrive and an example folder listing\n",
        "!ls -la /content/drive/MyDrive | sed -n '1,200p'"
      ],
      "metadata": {
        "id": "m88OGK7DuUOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install XGBoost (Colab)\n",
        "!pip install xgboost --quiet\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import xgboost as xgb\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ----------------------------\n",
        "# Helper: mount & set paths\n",
        "# ----------------------------\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# EDIT these to match exact filenames/locations you saw above:\n",
        "TRAIN_PATH = '/content/drive/MyDrive/train(1).csv'\n",
        "TEST_PATH  = '/content/drive/MyDrive/test.csv'\n",
        "\n",
        "# quick safety check:\n",
        "for p in (TRAIN_PATH, TEST_PATH):\n",
        "    if not os.path.exists(p):\n",
        "        raise FileNotFoundError(f\"File not found: {p} ‚Äî check the path with !ls /content/drive/MyDrive\")\n",
        "\n",
        "print(\"Data files found. Loading...\")\n",
        "\n",
        "# ----------------------------\n",
        "# Lightweight column-checker + safe defaults\n",
        "# ----------------------------\n",
        "# list of columns your feature creation expects (from your script)\n",
        "expected_cols = [\n",
        "    'Len_Circuit_inkm', 'Laps', 'Start_Position', 'Formula_Avg_Speed_kmh',\n",
        "    'Humidity_%', 'Corners_in_Lap', 'Tire_Degradation_Factor_per_Lap',\n",
        "    'Pit_Stop_Duration_Seconds', 'Ambient_Temperature_Celsius',\n",
        "    'Track_Temperature_Celsius', 'starts', 'finishes', 'with_points',\n",
        "    'podiums', 'wins', 'race_year', 'position', 'points',\n",
        "    # categorical\n",
        "    'Formula_category_x', 'Formula_Track_Condition', 'Tire_Compound',\n",
        "    'Penalty', 'Session', 'Formula_shortname', 'circuit_name',\n",
        "    'weather', 'track', 'air', 'ground'\n",
        "]\n",
        "\n",
        "# load (safe read)\n",
        "train_df = pd.read_csv(TRAIN_PATH)\n",
        "test_df  = pd.read_csv(TEST_PATH)\n",
        "\n",
        "print(f\"train shape: {train_df.shape}, test shape: {test_df.shape}\")\n",
        "\n",
        "# Add any missing numeric columns with sensible defaults (0 or median later)\n",
        "missing = [c for c in expected_cols if c not in train_df.columns]\n",
        "if missing:\n",
        "    print(f\"‚ö†Ô∏è  Warning: missing columns in train: {missing}\")\n",
        "    for c in missing:\n",
        "        # numeric-like defaults to zero; categorical default to 'Unknown'\n",
        "        if c in ['Formula_category_x','Formula_Track_Condition','Tire_Compound','Penalty','Session','Formula_shortname','circuit_name','weather','track','air','ground']:\n",
        "            train_df[c] = 'Unknown'\n",
        "            test_df[c] = 'Unknown'\n",
        "        else:\n",
        "            train_df[c] = 0\n",
        "            test_df[c] = 0\n",
        "\n",
        "# If Lap_Time_Seconds missing in train -> raise (target required)\n",
        "if 'Lap_Time_Seconds' not in train_df.columns:\n",
        "    raise KeyError(\"train.csv must contain 'Lap_Time_Seconds' as target column.\")\n",
        "\n",
        "# If train contains NaN targets, drop them\n",
        "if train_df['Lap_Time_Seconds'].isna().any():\n",
        "    cnt = train_df['Lap_Time_Seconds'].isna().sum()\n",
        "    print(f\"Removing {cnt} rows with missing Lap_Time_Seconds\")\n",
        "    train_df = train_df[train_df['Lap_Time_Seconds'].notna()].reset_index(drop=True)\n",
        "\n",
        "# =============================================================================\n",
        "# Replace fragile LabelEncoder usage with a saved mapping approach\n",
        "# This simple pattern stores mappings in self.label_encoders as dicts,\n",
        "# and on predict it maps unknown categories to a reserved value (e.g., 0).\n",
        "# =============================================================================\n",
        "class SafeLabelEncoder:\n",
        "    def __init__(self):\n",
        "        self.classes_ = []\n",
        "        self.mapping = {}\n",
        "        self.unknown_value = 0  # reserved code for unknowns\n",
        "\n",
        "    def fit(self, values):\n",
        "        vals = pd.Series(values).fillna('Unknown').astype(str)\n",
        "        cats = pd.Series(vals.unique())\n",
        "        # start mapping at 1 so 0 can mean \"Unknown\"\n",
        "        self.mapping = {v: i+1 for i, v in enumerate(sorted(cats))}\n",
        "        self.unknown_value = 0\n",
        "        return self\n",
        "\n",
        "    def transform(self, values):\n",
        "        vals = pd.Series(values).fillna('Unknown').astype(str)\n",
        "        return vals.map(lambda x: self.mapping.get(x, self.unknown_value)).astype(int)\n",
        "\n",
        "    def fit_transform(self, values):\n",
        "        self.fit(values)\n",
        "        return self.transform(values)\n",
        "\n",
        "# =============================================================================\n",
        "# Replace parts of your class preprocess_data where LabelEncoder used\n",
        "# I'll show a compact example of encoding step to paste into your class.\n",
        "# =============================================================================\n",
        "\n",
        "# Example snippet to use inside your AdvancedLapTimePredictionModel.preprocess_data:\n",
        "\"\"\"\n",
        "    # --- encoding categorical variables robustly ---\n",
        "    for col in categorical_cols:\n",
        "        if col in df.columns:\n",
        "            if is_training:\n",
        "                le = SafeLabelEncoder()\n",
        "                df[col] = le.fit_transform(df[col])\n",
        "                self.label_encoders[col] = le\n",
        "            else:\n",
        "                # map unseen to 0\n",
        "                le = self.label_encoders.get(col)\n",
        "                if le is None:\n",
        "                    # unexpected: encoder missing; fallback to zeros\n",
        "                    df[col] = 0\n",
        "                else:\n",
        "                    df[col] = le.transform(df[col])\n",
        "\"\"\"\n",
        "\n",
        "# =============================================================================\n",
        "# XGBoost performance defaults for large datasets\n",
        "# - tree_method='hist' (fast, lower memory)\n",
        "# - enable early_stopping during grid search or training when you provide eval_set\n",
        "# - if GPU available, set tree_method='gpu_hist' and predictor='gpu_predictor'\n",
        "# =============================================================================\n",
        "\n",
        "xgb_params_default = {\n",
        "    'n_estimators': 400,\n",
        "    'max_depth': 8,\n",
        "    'learning_rate': 0.1,\n",
        "    'subsample': 0.8,\n",
        "    'colsample_bytree': 0.8,\n",
        "    'random_state': 42,\n",
        "    'n_jobs': -1,\n",
        "    'verbosity': 1,\n",
        "    # for large datasets:\n",
        "    'tree_method': 'hist'   # change to 'gpu_hist' if GPU available\n",
        "}\n",
        "\n",
        "# If you want, you can now instantiate your model class and continue as before,\n",
        "# but ensure you replace your label encoder block with the SafeLabelEncoder logic above.\n",
        "\n",
        "print(\"Pre-checks complete ‚Äî you can now run the model training code (paste your class & call).\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1sgskmyuVCi",
        "outputId": "7f851751-dac6-4293-8756-931e9415711f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Data files found. Loading...\n",
            "train shape: (734002, 36), test shape: (314573, 35)\n",
            "Pre-checks complete ‚Äî you can now run the model training code (paste your class & call).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# RACING LAP TIME PREDICTION - OPTIMIZED XGBOOST MODEL\n",
        "# ============================================================================\n",
        "# Features:\n",
        "# - Single XGBoost model (optimized for 30-45 min training on 734K rows)\n",
        "# - Advanced feature engineering (23 new features)\n",
        "# - Google Drive integration\n",
        "# - Saves predictions immediately after training\n",
        "# - SafeLabelEncoder for robust categorical handling\n",
        "# ============================================================================\n",
        "\n",
        "# Install XGBoost\n",
        "!pip install xgboost --quiet\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import xgboost as xgb\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ============================================================================\n",
        "# SAFE LABEL ENCODER (handles unseen categories)\n",
        "# ============================================================================\n",
        "class SafeLabelEncoder:\n",
        "    \"\"\"Label encoder that handles unseen categories gracefully.\"\"\"\n",
        "    def __init__(self):\n",
        "        self.mapping = {}\n",
        "        self.unknown_value = 0\n",
        "\n",
        "    def fit(self, values):\n",
        "        vals = pd.Series(values).fillna('Unknown').astype(str)\n",
        "        unique_vals = sorted(vals.unique())\n",
        "        # Map to integers starting from 1 (0 reserved for unknown)\n",
        "        self.mapping = {v: i+1 for i, v in enumerate(unique_vals)}\n",
        "        return self\n",
        "\n",
        "    def transform(self, values):\n",
        "        vals = pd.Series(values).fillna('Unknown').astype(str)\n",
        "        return vals.map(lambda x: self.mapping.get(x, self.unknown_value)).astype(int)\n",
        "\n",
        "    def fit_transform(self, values):\n",
        "        self.fit(values)\n",
        "        return self.transform(values)\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# XGBOOST LAP TIME PREDICTION MODEL\n",
        "# ============================================================================\n",
        "class XGBoostLapTimePredictor:\n",
        "    \"\"\"\n",
        "    Optimized XGBoost model for racing lap time prediction.\n",
        "    Balanced for accuracy and speed (30-45 min training on 734K rows).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.scaler = StandardScaler()\n",
        "        self.label_encoders = {}\n",
        "        self.feature_columns = None\n",
        "        self.target_column = 'Lap_Time_Seconds'\n",
        "\n",
        "        # XGBoost optimized for 30-45 min training time on large dataset\n",
        "        self.model = xgb.XGBRegressor(\n",
        "            n_estimators=10000,           # Balanced (not too many, not too few)\n",
        "            max_depth=18,               # Deep enough to capture patterns\n",
        "            learning_rate=0.1,          # Standard learning rate\n",
        "            subsample=0.8,              # Use 80% of data per tree\n",
        "            colsample_bytree=0.8,       # Use 80% of features per tree\n",
        "            min_child_weight=3,         # Regularization\n",
        "            gamma=0.1,                  # Minimum loss reduction\n",
        "            reg_alpha=0.1,              # L1 regularization\n",
        "            reg_lambda=1.0,             # L2 regularization\n",
        "            tree_method='hist',         # Fast histogram-based algorithm\n",
        "            random_state=42,\n",
        "            n_jobs=-1,                  # Use all CPU cores\n",
        "            verbosity=1\n",
        "        )\n",
        "\n",
        "    def create_advanced_features(self, df):\n",
        "        \"\"\"\n",
        "        Create 23 advanced engineered features.\n",
        "        These capture complex relationships in the data.\n",
        "        \"\"\"\n",
        "        print(\"  Creating advanced features...\")\n",
        "\n",
        "        # Basic ratio features\n",
        "        df['Speed_to_Circuit_Ratio'] = df['Formula_Avg_Speed_kmh'] / (df['Len_Circuit_inkm'] + 0.001)\n",
        "        df['Total_Distance'] = df['Len_Circuit_inkm'] * df['Laps']\n",
        "        df['Temp_Difference'] = df['Track_Temperature_Celsius'] - df['Ambient_Temperature_Celsius']\n",
        "\n",
        "        # Performance rates\n",
        "        df['Win_Rate'] = df['wins'] / (df['starts'] + 1)\n",
        "        df['Podium_Rate'] = df['podiums'] / (df['starts'] + 1)\n",
        "        df['Points_Rate'] = df['with_points'] / (df['starts'] + 1)\n",
        "        df['Finish_Rate'] = df['finishes'] / (df['starts'] + 1)\n",
        "        df['Success_Rate'] = (df['wins'] + df['podiums']) / (df['starts'] + 1)\n",
        "        df['DNF_Rate'] = 1 - df['Finish_Rate']\n",
        "\n",
        "        # Interaction features (combining important factors)\n",
        "        df['Speed_x_Corners'] = df['Formula_Avg_Speed_kmh'] * df['Corners_in_Lap']\n",
        "        df['Circuit_x_Laps'] = df['Len_Circuit_inkm'] * df['Laps']\n",
        "        df['Temp_x_Humidity'] = df['Track_Temperature_Celsius'] * df['Humidity_%']\n",
        "        df['Degradation_x_Distance'] = df['Tire_Degradation_Factor_per_Lap'] * df['Total_Distance']\n",
        "        df['PitStop_x_Laps'] = df['Pit_Stop_Duration_Seconds'] * df['Laps']\n",
        "        df['Humidity_x_Temp_Diff'] = df['Humidity_%'] * df['Temp_Difference']\n",
        "\n",
        "        # Polynomial features (non-linear relationships)\n",
        "        df['Speed_Squared'] = df['Formula_Avg_Speed_kmh'] ** 2\n",
        "        df['Corners_Squared'] = df['Corners_in_Lap'] ** 2\n",
        "        df['Temp_Squared'] = df['Track_Temperature_Celsius'] ** 2\n",
        "\n",
        "        # Circuit complexity metrics\n",
        "        df['Circuit_Complexity'] = df['Corners_in_Lap'] / (df['Len_Circuit_inkm'] + 0.001)\n",
        "        df['Avg_Speed_Per_Corner'] = df['Formula_Avg_Speed_kmh'] / (df['Corners_in_Lap'] + 1)\n",
        "\n",
        "        # Experience features\n",
        "        df['Experience_Level'] = np.log1p(df['starts'])\n",
        "        df['Avg_Points_Per_Race'] = df['points'] / (df['starts'] + 1)\n",
        "        df['Win_to_Start_Ratio'] = df['wins'] / (df['starts'] + 1)\n",
        "\n",
        "        return df\n",
        "\n",
        "    def preprocess_data(self, df, is_training=True):\n",
        "        \"\"\"\n",
        "        Preprocess data: handle missing values, encode categoricals, engineer features.\n",
        "        \"\"\"\n",
        "        print(f\"  Preprocessing data... (shape: {df.shape})\")\n",
        "        df = df.copy()\n",
        "\n",
        "        # Define column types\n",
        "        categorical_cols = [\n",
        "            'Formula_category_x', 'Formula_Track_Condition', 'Tire_Compound',\n",
        "            'Penalty', 'Session', 'Formula_shortname', 'circuit_name',\n",
        "            'weather', 'track', 'air', 'ground'\n",
        "        ]\n",
        "\n",
        "        numerical_cols = [\n",
        "            'Len_Circuit_inkm', 'Laps', 'Start_Position', 'Formula_Avg_Speed_kmh',\n",
        "            'Humidity_%', 'Corners_in_Lap', 'Tire_Degradation_Factor_per_Lap',\n",
        "            'Pit_Stop_Duration_Seconds', 'Ambient_Temperature_Celsius',\n",
        "            'Track_Temperature_Celsius', 'starts', 'finishes', 'with_points',\n",
        "            'podiums', 'wins', 'race_year', 'position', 'points'\n",
        "        ]\n",
        "\n",
        "        # Handle missing values\n",
        "        print(\"  Filling missing values...\")\n",
        "        for col in numerical_cols:\n",
        "            if col in df.columns:\n",
        "                df[col] = df[col].fillna(df[col].median())\n",
        "\n",
        "        for col in categorical_cols:\n",
        "            if col in df.columns:\n",
        "                df[col] = df[col].fillna('Unknown')\n",
        "\n",
        "        # Encode categorical variables\n",
        "        print(\"  Encoding categorical variables...\")\n",
        "        for col in categorical_cols:\n",
        "            if col in df.columns:\n",
        "                if is_training:\n",
        "                    self.label_encoders[col] = SafeLabelEncoder()\n",
        "                    df[col] = self.label_encoders[col].fit_transform(df[col])\n",
        "                else:\n",
        "                    if col in self.label_encoders:\n",
        "                        df[col] = self.label_encoders[col].transform(df[col])\n",
        "                    else:\n",
        "                        df[col] = 0\n",
        "\n",
        "        # Create advanced features\n",
        "        df = self.create_advanced_features(df)\n",
        "\n",
        "        # Define all features to use\n",
        "        engineered_features = [\n",
        "            'Speed_to_Circuit_Ratio', 'Total_Distance', 'Temp_Difference',\n",
        "            'Win_Rate', 'Podium_Rate', 'Points_Rate', 'Finish_Rate',\n",
        "            'Success_Rate', 'DNF_Rate',\n",
        "            'Speed_x_Corners', 'Circuit_x_Laps', 'Temp_x_Humidity',\n",
        "            'Degradation_x_Distance', 'PitStop_x_Laps', 'Humidity_x_Temp_Diff',\n",
        "            'Speed_Squared', 'Corners_Squared', 'Temp_Squared',\n",
        "            'Circuit_Complexity', 'Avg_Speed_Per_Corner',\n",
        "            'Experience_Level', 'Avg_Points_Per_Race', 'Win_to_Start_Ratio'\n",
        "        ]\n",
        "\n",
        "        all_features = numerical_cols + categorical_cols + engineered_features\n",
        "        all_features = [col for col in all_features if col in df.columns]\n",
        "\n",
        "        if is_training:\n",
        "            self.feature_columns = all_features\n",
        "\n",
        "        # Ensure all required columns exist\n",
        "        for col in self.feature_columns:\n",
        "            if col not in df.columns:\n",
        "                df[col] = 0\n",
        "\n",
        "        print(f\"  Total features: {len(self.feature_columns)} \"\n",
        "              f\"(Original: {len(numerical_cols + categorical_cols)}, Engineered: {len(engineered_features)})\")\n",
        "\n",
        "        return df[self.feature_columns]\n",
        "\n",
        "    def train(self, train_df):\n",
        "        \"\"\"Train the XGBoost model.\"\"\"\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(\"TRAINING XGBOOST MODEL\")\n",
        "        print(f\"{'='*70}\")\n",
        "\n",
        "        # Preprocess training data\n",
        "        print(\"\\n[1/4] Preprocessing training data...\")\n",
        "        X_train = self.preprocess_data(train_df, is_training=True)\n",
        "        y_train = train_df[self.target_column]\n",
        "\n",
        "        print(f\"\\n  ‚úì Training samples: {X_train.shape[0]:,}\")\n",
        "        print(f\"  ‚úì Total features: {X_train.shape[1]}\")\n",
        "        print(f\"  ‚úì Target range: {y_train.min():.2f} - {y_train.max():.2f} seconds\")\n",
        "        print(f\"  ‚úì Target mean: {y_train.mean():.2f} seconds\")\n",
        "\n",
        "        # Scale features\n",
        "        print(\"\\n[2/4] Scaling features...\")\n",
        "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
        "        print(\"  ‚úì Features scaled using StandardScaler\")\n",
        "\n",
        "        # Train model\n",
        "        print(\"\\n[3/4] Training XGBoost model...\")\n",
        "        print(\"  (This will take approximately 30-45 minutes for 734K rows)\")\n",
        "        print(\"  Progress will be shown below:\\n\")\n",
        "\n",
        "        self.model.fit(X_train_scaled, y_train)\n",
        "\n",
        "        # Evaluate on training data\n",
        "        print(\"\\n[4/4] Evaluating model performance...\")\n",
        "        y_train_pred = self.model.predict(X_train_scaled)\n",
        "        train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
        "\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(\"TRAINING RESULTS\")\n",
        "        print(f\"{'='*70}\")\n",
        "        print(f\"  Training RMSE: {train_rmse:.4f} seconds\")\n",
        "\n",
        "        # Interpret RMSE\n",
        "        if train_rmse < 0.10:\n",
        "            print(f\"  üéâ EXCELLENT: Very accurate predictions!\")\n",
        "        elif train_rmse < 0.3:\n",
        "            print(f\"  ‚úÖ VERY GOOD: Strong performance!\")\n",
        "        elif train_rmse < 0.5:\n",
        "            print(f\"  ‚úÖ GOOD: Solid predictions\")\n",
        "        else:\n",
        "            print(f\"  ‚ö†Ô∏è  MODERATE: Room for improvement\")\n",
        "\n",
        "        # Feature importance\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(\"TOP 25 MOST IMPORTANT FEATURES\")\n",
        "        print(f\"{'='*70}\")\n",
        "\n",
        "        importance_df = pd.DataFrame({\n",
        "            'feature': self.feature_columns,\n",
        "            'importance': self.model.feature_importances_\n",
        "        }).sort_values('importance', ascending=False)\n",
        "\n",
        "        for idx, row in importance_df.head(25).iterrows():\n",
        "            # Mark engineered features\n",
        "            is_engineered = any(marker in row['feature'] for marker in\n",
        "                ['_x_', '_Squared', 'Rate', 'Ratio', 'Success', 'DNF',\n",
        "                 'Complexity', 'Experience', 'Avg_'])\n",
        "            marker = \"üÜï\" if is_engineered else \"  \"\n",
        "            print(f\"{marker} {row['feature']:50s} {row['importance']:.4f}\")\n",
        "\n",
        "        self.feature_importance = importance_df\n",
        "        return train_rmse\n",
        "\n",
        "    def predict(self, df):\n",
        "        \"\"\"Generate predictions on new data.\"\"\"\n",
        "        X = self.preprocess_data(df, is_training=False)\n",
        "        X_scaled = self.scaler.transform(X)\n",
        "        return self.model.predict(X_scaled)\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# MAIN EXECUTION\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\"\"\n",
        "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "‚ïë         OPTIMIZED XGBOOST LAP TIME PREDICTION                        ‚ïë\n",
        "‚ïë         ‚Ä¢ Single XGBoost model (30-45 min training)                  ‚ïë\n",
        "‚ïë         ‚Ä¢ 23 advanced engineered features                            ‚ïë\n",
        "‚ïë         ‚Ä¢ Google Drive integration                                   ‚ïë\n",
        "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "\"\"\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 1: MOUNT GOOGLE DRIVE & LOAD DATA\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"STEP 1: MOUNTING GOOGLE DRIVE & LOADING DATA\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# ============================================================================\n",
        "# CONFIGURE YOUR FILE PATHS HERE\n",
        "# ============================================================================\n",
        "TRAIN_PATH = '/content/drive/MyDrive/train(1).csv'\n",
        "TEST_PATH = '/content/drive/MyDrive/test.csv'\n",
        "OUTPUT_PATH = '/content/drive/MyDrive/xgboost_predictions.csv'\n",
        "\n",
        "# Verify files exist\n",
        "print(\"\\nVerifying file paths...\")\n",
        "for path in [TRAIN_PATH, TEST_PATH]:\n",
        "    if not os.path.exists(path):\n",
        "        raise FileNotFoundError(f\"‚ùå File not found: {path}\\n\"\n",
        "                              f\"   Please check your file paths!\")\n",
        "\n",
        "print(f\"\\n‚úì All files found!\")\n",
        "print(f\"  üìÇ Train: {TRAIN_PATH}\")\n",
        "print(f\"  üìÇ Test:  {TEST_PATH}\")\n",
        "print(f\"  üìÇ Output: {OUTPUT_PATH}\")\n",
        "\n",
        "# Load training data\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"Loading training data...\")\n",
        "print(f\"{'='*70}\")\n",
        "train_df = pd.read_csv(TRAIN_PATH)\n",
        "print(f\"‚úì Loaded: {train_df.shape[0]:,} rows √ó {train_df.shape[1]} columns\")\n",
        "\n",
        "# Handle missing target values\n",
        "if 'Lap_Time_Seconds' not in train_df.columns:\n",
        "    raise ValueError(\"‚ùå Training data must contain 'Lap_Time_Seconds' column!\")\n",
        "\n",
        "missing_targets = train_df['Lap_Time_Seconds'].isnull().sum()\n",
        "if missing_targets > 0:\n",
        "    print(f\"\\n‚ö†Ô∏è  Found {missing_targets:,} rows with missing lap times\")\n",
        "    print(f\"   Removing these rows...\")\n",
        "    train_df = train_df[train_df['Lap_Time_Seconds'].notna()].reset_index(drop=True)\n",
        "    print(f\"‚úì Cleaned training data: {train_df.shape[0]:,} rows remaining\")\n",
        "\n",
        "# Display training data statistics\n",
        "print(f\"\\nüìä Training Data Statistics:\")\n",
        "print(f\"   Lap time range: {train_df['Lap_Time_Seconds'].min():.2f} - \"\n",
        "      f\"{train_df['Lap_Time_Seconds'].max():.2f} seconds\")\n",
        "print(f\"   Mean lap time: {train_df['Lap_Time_Seconds'].mean():.2f} seconds\")\n",
        "print(f\"   Std deviation: {train_df['Lap_Time_Seconds'].std():.2f} seconds\")\n",
        "\n",
        "# Load test data\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"Loading test data...\")\n",
        "print(f\"{'='*70}\")\n",
        "test_df = pd.read_csv(TEST_PATH)\n",
        "print(f\"‚úì Loaded: {test_df.shape[0]:,} rows √ó {test_df.shape[1]} columns\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 2: TRAIN XGBOOST MODEL\n",
        "# ============================================================================\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"STEP 2: TRAINING XGBOOST MODEL\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"\\n‚è±Ô∏è  Estimated training time: 30-45 minutes\")\n",
        "print(f\"üí° Tip: Go grab a coffee! ‚òï\\n\")\n",
        "\n",
        "# Initialize and train model\n",
        "model = XGBoostLapTimePredictor()\n",
        "train_rmse = model.train(train_df)\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 3: GENERATE PREDICTIONS\n",
        "# ============================================================================\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"STEP 3: GENERATING TEST PREDICTIONS\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "print(\"\\nGenerating predictions on test data...\")\n",
        "test_predictions = model.predict(test_df)\n",
        "\n",
        "# Create results dataframe\n",
        "results_df = pd.DataFrame({\n",
        "    'Predicted_Lap_Time': test_predictions\n",
        "})\n",
        "\n",
        "# Add ID column if exists in test data\n",
        "if 'id' in test_df.columns:\n",
        "    results_df.insert(0, 'id', test_df['id'].values)\n",
        "    print(f\"‚úì Added ID column from test data\")\n",
        "\n",
        "print(f\"\\n‚úì Generated {len(test_predictions):,} predictions\")\n",
        "print(f\"\\nüìä Prediction Statistics:\")\n",
        "print(f\"   Range: {test_predictions.min():.2f} - {test_predictions.max():.2f} seconds\")\n",
        "print(f\"   Mean: {test_predictions.mean():.2f} seconds\")\n",
        "print(f\"   Std: {test_predictions.std():.2f} seconds\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 4: SAVE PREDICTIONS TO GOOGLE DRIVE\n",
        "# ============================================================================\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"STEP 4: SAVING PREDICTIONS\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "results_df.to_csv(OUTPUT_PATH, index=False)\n",
        "print(f\"\\nüíæ SUCCESS! Predictions saved to:\")\n",
        "print(f\"   {OUTPUT_PATH}\")\n",
        "\n",
        "# Display sample predictions\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"SAMPLE PREDICTIONS (First 10 rows)\")\n",
        "print(f\"{'='*70}\")\n",
        "print(results_df.head(10).to_string(index=False))\n",
        "\n",
        "# ============================================================================\n",
        "# FINAL SUMMARY\n",
        "# ============================================================================\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"üéâ TRAINING & PREDICTION COMPLETE!\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "print(f\"\\n‚úÖ Summary:\")\n",
        "print(f\"   ‚Ä¢ Model: XGBoost with advanced feature engineering\")\n",
        "print(f\"   ‚Ä¢ Training RMSE: {train_rmse:.4f} seconds\")\n",
        "print(f\"   ‚Ä¢ Training samples: {train_df.shape[0]:,}\")\n",
        "print(f\"   ‚Ä¢ Test predictions: {len(test_predictions):,}\")\n",
        "print(f\"   ‚Ä¢ Total features used: {len(model.feature_columns)}\")\n",
        "print(f\"   ‚Ä¢ Engineered features: 23\")\n",
        "\n",
        "print(f\"\\nüìÅ Output file saved to your Google Drive:\")\n",
        "print(f\"   {OUTPUT_PATH}\")\n",
        "\n",
        "print(f\"\\nüí° Next Steps:\")\n",
        "print(f\"   1. Download the CSV from your Google Drive\")\n",
        "print(f\"   2. Check the predictions in Excel/Sheets\")\n",
        "print(f\"   3. Submit to your competition/evaluation platform\")\n",
        "\n",
        "print(f\"\\nüöÄ Model is ready for production use!\")\n",
        "print(f\"   Files are safely stored in Google Drive - no data loss risk!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1YB4yJDvnC6",
        "outputId": "e2104260-ec84-4a7a-cc3f-54390a4d1cc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
            "‚ïë         OPTIMIZED XGBOOST LAP TIME PREDICTION                        ‚ïë\n",
            "‚ïë         ‚Ä¢ Single XGBoost model (30-45 min training)                  ‚ïë\n",
            "‚ïë         ‚Ä¢ 23 advanced engineered features                            ‚ïë\n",
            "‚ïë         ‚Ä¢ Google Drive integration                                   ‚ïë\n",
            "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
            "\n",
            "\n",
            "======================================================================\n",
            "STEP 1: MOUNTING GOOGLE DRIVE & LOADING DATA\n",
            "======================================================================\n",
            "Mounted at /content/drive\n",
            "\n",
            "Verifying file paths...\n",
            "\n",
            "‚úì All files found!\n",
            "  üìÇ Train: /content/drive/MyDrive/train(1).csv\n",
            "  üìÇ Test:  /content/drive/MyDrive/test.csv\n",
            "  üìÇ Output: /content/drive/MyDrive/xgboost_predictions.csv\n",
            "\n",
            "======================================================================\n",
            "Loading training data...\n",
            "======================================================================\n",
            "‚úì Loaded: 734,002 rows √ó 36 columns\n",
            "\n",
            "üìä Training Data Statistics:\n",
            "   Lap time range: 70.00 - 110.00 seconds\n",
            "   Mean lap time: 90.00 seconds\n",
            "   Std deviation: 11.53 seconds\n",
            "\n",
            "======================================================================\n",
            "Loading test data...\n",
            "======================================================================\n",
            "‚úì Loaded: 314,573 rows √ó 35 columns\n",
            "\n",
            "======================================================================\n",
            "STEP 2: TRAINING XGBOOST MODEL\n",
            "======================================================================\n",
            "\n",
            "‚è±Ô∏è  Estimated training time: 30-45 minutes\n",
            "üí° Tip: Go grab a coffee! ‚òï\n",
            "\n",
            "\n",
            "======================================================================\n",
            "TRAINING XGBOOST MODEL\n",
            "======================================================================\n",
            "\n",
            "[1/4] Preprocessing training data...\n",
            "  Preprocessing data... (shape: (734002, 36))\n",
            "  Filling missing values...\n",
            "  Encoding categorical variables...\n",
            "  Creating advanced features...\n",
            "  Total features: 52 (Original: 29, Engineered: 23)\n",
            "\n",
            "  ‚úì Training samples: 734,002\n",
            "  ‚úì Total features: 52\n",
            "  ‚úì Target range: 70.00 - 110.00 seconds\n",
            "  ‚úì Target mean: 90.00 seconds\n",
            "\n",
            "[2/4] Scaling features...\n",
            "  ‚úì Features scaled using StandardScaler\n",
            "\n",
            "[3/4] Training XGBoost model...\n",
            "  (This will take approximately 30-45 minutes for 734K rows)\n",
            "  Progress will be shown below:\n",
            "\n",
            "\n",
            "[4/4] Evaluating model performance...\n",
            "\n",
            "======================================================================\n",
            "TRAINING RESULTS\n",
            "======================================================================\n",
            "  Training RMSE: 0.1317 seconds\n",
            "  ‚úÖ VERY GOOD: Strong performance!\n",
            "\n",
            "======================================================================\n",
            "TOP 25 MOST IMPORTANT FEATURES\n",
            "======================================================================\n",
            "üÜï Temp_Squared                                       0.0474\n",
            "üÜï Avg_Points_Per_Race                                0.0411\n",
            "üÜï Points_Rate                                        0.0400\n",
            "üÜï Win_to_Start_Ratio                                 0.0398\n",
            "üÜï Success_Rate                                       0.0398\n",
            "   Formula_shortname                                  0.0387\n",
            "   Temp_Difference                                    0.0382\n",
            "üÜï DNF_Rate                                           0.0379\n",
            "üÜï Podium_Rate                                        0.0371\n",
            "   track                                              0.0363\n",
            "üÜï Win_Rate                                           0.0339\n",
            "   position                                           0.0332\n",
            "üÜï Finish_Rate                                        0.0326\n",
            "   finishes                                           0.0324\n",
            "   weather                                            0.0321\n",
            "   air                                                0.0320\n",
            "üÜï Experience_Level                                   0.0317\n",
            "   Track_Temperature_Celsius                          0.0315\n",
            "   circuit_name                                       0.0312\n",
            "   Ambient_Temperature_Celsius                        0.0304\n",
            "   points                                             0.0301\n",
            "   ground                                             0.0294\n",
            "   wins                                               0.0289\n",
            "   race_year                                          0.0279\n",
            "   with_points                                        0.0274\n",
            "\n",
            "======================================================================\n",
            "STEP 3: GENERATING TEST PREDICTIONS\n",
            "======================================================================\n",
            "\n",
            "Generating predictions on test data...\n",
            "  Preprocessing data... (shape: (314573, 35))\n",
            "  Filling missing values...\n",
            "  Encoding categorical variables...\n",
            "  Creating advanced features...\n",
            "  Total features: 52 (Original: 29, Engineered: 23)\n",
            "‚úì Added ID column from test data\n",
            "\n",
            "‚úì Generated 314,573 predictions\n",
            "\n",
            "üìä Prediction Statistics:\n",
            "   Range: 68.54 - 110.85 seconds\n",
            "   Mean: 89.98 seconds\n",
            "   Std: 11.39 seconds\n",
            "\n",
            "======================================================================\n",
            "STEP 4: SAVING PREDICTIONS\n",
            "======================================================================\n",
            "\n",
            "üíæ SUCCESS! Predictions saved to:\n",
            "   /content/drive/MyDrive/xgboost_predictions.csv\n",
            "\n",
            "======================================================================\n",
            "SAMPLE PREDICTIONS (First 10 rows)\n",
            "======================================================================\n",
            "    id  Predicted_Lap_Time\n",
            "781975          108.232162\n",
            "937738           86.069450\n",
            "907829           87.852547\n",
            "784629           95.481621\n",
            "662461           98.663742\n",
            "280140           90.576828\n",
            "355573           97.050949\n",
            "749980           96.306000\n",
            "374754           75.186783\n",
            " 17328           94.789642\n",
            "\n",
            "======================================================================\n",
            "üéâ TRAINING & PREDICTION COMPLETE!\n",
            "======================================================================\n",
            "\n",
            "‚úÖ Summary:\n",
            "   ‚Ä¢ Model: XGBoost with advanced feature engineering\n",
            "   ‚Ä¢ Training RMSE: 0.1317 seconds\n",
            "   ‚Ä¢ Training samples: 734,002\n",
            "   ‚Ä¢ Test predictions: 314,573\n",
            "   ‚Ä¢ Total features used: 52\n",
            "   ‚Ä¢ Engineered features: 23\n",
            "\n",
            "üìÅ Output file saved to your Google Drive:\n",
            "   /content/drive/MyDrive/xgboost_predictions.csv\n",
            "\n",
            "üí° Next Steps:\n",
            "   1. Download the CSV from your Google Drive\n",
            "   2. Check the predictions in Excel/Sheets\n",
            "   3. Submit to your competition/evaluation platform\n",
            "\n",
            "üöÄ Model is ready for production use!\n",
            "   Files are safely stored in Google Drive - no data loss risk!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Previous Models 3x Algo"
      ],
      "metadata": {
        "id": "vlemuCvZvmws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Pya3ffBoGRAc",
        "outputId": "e672f2dd-0648-4c26-d29e-d04be84934b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
            "‚ïë    ADVANCED RACING LAP TIME PREDICTION WITH XGBOOST                 ‚ïë\n",
            "‚ïë    ‚Ä¢ Multiple Algorithms (RF, GB, XGBoost)                           ‚ïë\n",
            "‚ïë    ‚Ä¢ Hyperparameter Tuning                                           ‚ïë\n",
            "‚ïë    ‚Ä¢ Advanced Feature Engineering                                    ‚ïë\n",
            "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
            "\n",
            "\n",
            "======================================================================\n",
            "STEP 1: LOADING DATASETS\n",
            "======================================================================\n",
            "\n",
            "Loading training data from: train (1).csv\n",
            "‚úì Training data loaded: 734,002 rows √ó 36 columns\n",
            "\n",
            "Loading test data from: test.csv\n",
            "‚úì Test data loaded: 314,573 rows √ó 35 columns\n",
            "\n",
            "======================================================================\n",
            "STEP 2: TRAINING MODELS\n",
            "======================================================================\n",
            "\n",
            "üöÄ TRAINING MODE: Quick (No Hyperparameter Tuning)\n",
            "   Change tune_hyperparameters=True for grid search (much slower)\n",
            "\n",
            "######################################################################\n",
            "# TRAINING: RANDOM FOREST\n",
            "######################################################################\n",
            "\n",
            "======================================================================\n",
            "TRAINING RANDOM FOREST MODEL\n",
            "======================================================================\n",
            "\n",
            "[1/4] Preprocessing training data...\n",
            "  Preprocessing data... (shape: (734002, 36))\n",
            "  Handling missing values...\n",
            "  Encoding categorical variables...\n",
            "  Creating advanced engineered features...\n",
            "  Total features: 52 (23 engineered)\n",
            "  Training samples: 734,002\n",
            "  Features: 52\n",
            "  Target range: 70.00 - 110.00 seconds\n",
            "\n",
            "[2/4] Scaling features...\n",
            "\n",
            "[3/4] Training model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   46.7s\n",
            "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  3.4min\n",
            "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  5.3min finished\n",
            "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[4/4] Evaluating model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    2.1s\n",
            "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    9.6s\n",
            "[Parallel(n_jobs=4)]: Done 300 out of 300 | elapsed:   14.9s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "MODEL PERFORMANCE METRICS\n",
            "======================================================================\n",
            "  Train Rmse               : 3.855 seconds\n",
            "\n",
            "======================================================================\n",
            "TOP 20 MOST IMPORTANT FEATURES\n",
            "======================================================================\n",
            "   Pit_Stop_Duration_Seconds                     0.0584\n",
            "   Ambient_Temperature_Celsius                   0.0547\n",
            "   Temp_Difference                               0.0540\n",
            "üÜï Temp_Squared                                  0.0515\n",
            "   Track_Temperature_Celsius                     0.0511\n",
            "   Tire_Degradation_Factor_per_Lap               0.0488\n",
            "   race_year                                     0.0425\n",
            "   circuit_name                                  0.0386\n",
            "   Formula_shortname                             0.0377\n",
            "   position                                      0.0360\n",
            "   Avg_Points_Per_Race                           0.0338\n",
            "üÜï Corners_Squared                               0.0309\n",
            "   Corners_in_Lap                                0.0309\n",
            "   Points_Rate                                   0.0303\n",
            "   Finish_Rate                                   0.0287\n",
            "üÜï DNF_Rate                                      0.0287\n",
            "   ground                                        0.0281\n",
            "   air                                           0.0255\n",
            "   finishes                                      0.0253\n",
            "   starts                                        0.0253\n",
            "\n",
            "######################################################################\n",
            "# TRAINING: GRADIENT BOOSTING\n",
            "######################################################################\n",
            "\n",
            "======================================================================\n",
            "TRAINING GRADIENT BOOSTING MODEL\n",
            "======================================================================\n",
            "\n",
            "[1/4] Preprocessing training data...\n",
            "  Preprocessing data... (shape: (734002, 36))\n",
            "  Handling missing values...\n",
            "  Encoding categorical variables...\n",
            "  Creating advanced engineered features...\n",
            "  Total features: 52 (23 engineered)\n",
            "  Training samples: 734,002\n",
            "  Features: 52\n",
            "  Target range: 70.00 - 110.00 seconds\n",
            "\n",
            "[2/4] Scaling features...\n",
            "\n",
            "[3/4] Training model...\n",
            "      Iter       Train Loss      OOB Improve   Remaining Time \n",
            "         1         132.2791           0.6240           68.79m\n",
            "         2         131.8241           0.5510           68.33m\n",
            "         3         131.1960           0.7022           68.39m\n",
            "         4         130.6625           0.3752           68.03m\n",
            "         5         130.2256           1.0183           67.69m\n",
            "         6         129.6156          -0.1676           67.41m\n",
            "         7         129.1597           0.6549           67.11m\n",
            "         8         128.6171           0.1204           66.95m\n",
            "         9         128.1267           0.7987           66.71m\n",
            "        10         128.0391           1.0180           66.49m\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2626453461.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    443\u001b[0m     )\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m     \u001b[0mtrain_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m     results_summary[model_name] = {\n\u001b[1;32m    447\u001b[0m         \u001b[0;34m'model'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2626453461.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_df, validation_df)\u001b[0m\n\u001b[1;32m    289\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"     {param}: {value}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;31m# Evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m         \u001b[0;31m# fit the boosting stages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         n_stages = self._fit_stages(\n\u001b[0m\u001b[1;32m    788\u001b[0m             \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m             \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m             \u001b[0;31m# fit next stage of trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 883\u001b[0;31m             raw_predictions = self._fit_stage(\n\u001b[0m\u001b[1;32m    884\u001b[0m                 \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_csc\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX_csc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             tree.fit(\n\u001b[0m\u001b[1;32m    490\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_g_view\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1402\u001b[0m         \"\"\"\n\u001b[1;32m   1403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1404\u001b[0;31m         super()._fit(\n\u001b[0m\u001b[1;32m   1405\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    470\u001b[0m             )\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing_values_in_feature_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# RACING LAP TIME PREDICTION - ADVANCED MODEL WITH XGBOOST\n",
        "# ============================================================================\n",
        "# Features:\n",
        "# 1. Multiple algorithms: Random Forest, Gradient Boosting, XGBoost\n",
        "# 2. Hyperparameter tuning with GridSearchCV\n",
        "# 3. Advanced feature engineering (interactions, polynomials)\n",
        "# 4. Optimized for large datasets (700K+ rows)\n",
        "# ============================================================================\n",
        "\n",
        "# Install XGBoost\n",
        "!pip install xgboost --quiet\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, PolynomialFeatures\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import xgboost as xgb\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class AdvancedLapTimePredictionModel:\n",
        "    \"\"\"\n",
        "    Advanced ML model for predicting racing lap times.\n",
        "    Includes XGBoost, hyperparameter tuning, and feature engineering.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_type='xgboost', tune_hyperparameters=False):\n",
        "        \"\"\"\n",
        "        Initialize the model.\n",
        "\n",
        "        Args:\n",
        "            model_type: 'random_forest', 'gradient_boosting', or 'xgboost'\n",
        "            tune_hyperparameters: Whether to perform grid search\n",
        "        \"\"\"\n",
        "        self.model_type = model_type\n",
        "        self.tune_hyperparameters = tune_hyperparameters\n",
        "        self.scaler = StandardScaler()\n",
        "        self.label_encoders = {}\n",
        "        self.feature_columns = None\n",
        "        self.target_column = 'Lap_Time_Seconds'\n",
        "\n",
        "        # Initialize model based on type\n",
        "        if model_type == 'random_forest':\n",
        "            if tune_hyperparameters:\n",
        "                self.model = RandomForestRegressor(random_state=42, n_jobs=-1, verbose=0)\n",
        "                self.param_grid = {\n",
        "                    'n_estimators': [200, 300],\n",
        "                    'max_depth': [15, 20, 25],\n",
        "                    'min_samples_split': [5, 10],\n",
        "                    'min_samples_leaf': [2, 4],\n",
        "                    'max_features': ['sqrt', 'log2']\n",
        "                }\n",
        "            else:\n",
        "                self.model = RandomForestRegressor(\n",
        "                    n_estimators=300,\n",
        "                    max_depth=25,\n",
        "                    min_samples_split=5,\n",
        "                    min_samples_leaf=2,\n",
        "                    max_features='sqrt',\n",
        "                    random_state=42,\n",
        "                    n_jobs=-1,\n",
        "                    verbose=1\n",
        "                )\n",
        "\n",
        "        elif model_type == 'gradient_boosting':\n",
        "            if tune_hyperparameters:\n",
        "                self.model = GradientBoostingRegressor(random_state=42, verbose=0)\n",
        "                self.param_grid = {\n",
        "                    'n_estimators': [200, 300],\n",
        "                    'max_depth': [5, 8, 10],\n",
        "                    'learning_rate': [0.05, 0.1, 0.15],\n",
        "                    'subsample': [0.7, 0.8, 0.9]\n",
        "                }\n",
        "            else:\n",
        "                self.model = GradientBoostingRegressor(\n",
        "                    n_estimators=300,\n",
        "                    max_depth=8,\n",
        "                    learning_rate=0.1,\n",
        "                    subsample=0.8,\n",
        "                    random_state=42,\n",
        "                    verbose=1\n",
        "                )\n",
        "\n",
        "        elif model_type == 'xgboost':\n",
        "            if tune_hyperparameters:\n",
        "                self.model = xgb.XGBRegressor(random_state=42, n_jobs=-1, verbosity=0)\n",
        "                self.param_grid = {\n",
        "                    'n_estimators': [200, 300, 400],\n",
        "                    'max_depth': [6, 8, 10],\n",
        "                    'learning_rate': [0.05, 0.1, 0.15],\n",
        "                    'subsample': [0.7, 0.8, 0.9],\n",
        "                    'colsample_bytree': [0.7, 0.8, 0.9]\n",
        "                }\n",
        "            else:\n",
        "                self.model = xgb.XGBRegressor(\n",
        "                    n_estimators=300,\n",
        "                    max_depth=8,\n",
        "                    learning_rate=0.1,\n",
        "                    subsample=0.8,\n",
        "                    colsample_bytree=0.8,\n",
        "                    random_state=42,\n",
        "                    n_jobs=-1,\n",
        "                    verbosity=1\n",
        "                )\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown model type: {model_type}\")\n",
        "\n",
        "    def create_advanced_features(self, df):\n",
        "        \"\"\"\n",
        "        Create advanced engineered features.\n",
        "\n",
        "        Args:\n",
        "            df: Input dataframe\n",
        "\n",
        "        Returns:\n",
        "            DataFrame with new features\n",
        "        \"\"\"\n",
        "        # Basic engineered features\n",
        "        df['Speed_to_Circuit_Ratio'] = df['Formula_Avg_Speed_kmh'] / (df['Len_Circuit_inkm'] + 0.001)\n",
        "        df['Total_Distance'] = df['Len_Circuit_inkm'] * df['Laps']\n",
        "        df['Temp_Difference'] = df['Track_Temperature_Celsius'] - df['Ambient_Temperature_Celsius']\n",
        "        df['Win_Rate'] = df['wins'] / (df['starts'] + 1)\n",
        "        df['Podium_Rate'] = df['podiums'] / (df['starts'] + 1)\n",
        "        df['Points_Rate'] = df['with_points'] / (df['starts'] + 1)\n",
        "        df['Finish_Rate'] = df['finishes'] / (df['starts'] + 1)\n",
        "\n",
        "        # ADVANCED FEATURES - NEW!\n",
        "\n",
        "        # 1. Interaction features (combining important factors)\n",
        "        df['Speed_x_Corners'] = df['Formula_Avg_Speed_kmh'] * df['Corners_in_Lap']\n",
        "        df['Circuit_x_Laps'] = df['Len_Circuit_inkm'] * df['Laps']\n",
        "        df['Temp_x_Humidity'] = df['Track_Temperature_Celsius'] * df['Humidity_%']\n",
        "        df['Degradation_x_Distance'] = df['Tire_Degradation_Factor_per_Lap'] * df['Total_Distance']\n",
        "        df['PitStop_x_Laps'] = df['Pit_Stop_Duration_Seconds'] * df['Laps']\n",
        "\n",
        "        # 2. Squared features (non-linear relationships)\n",
        "        df['Speed_Squared'] = df['Formula_Avg_Speed_kmh'] ** 2\n",
        "        df['Corners_Squared'] = df['Corners_in_Lap'] ** 2\n",
        "        df['Temp_Squared'] = df['Track_Temperature_Celsius'] ** 2\n",
        "\n",
        "        # 3. Performance indicators\n",
        "        df['Success_Rate'] = (df['wins'] + df['podiums']) / (df['starts'] + 1)\n",
        "        df['Avg_Points_Per_Race'] = df['points'] / (df['starts'] + 1)\n",
        "        df['DNF_Rate'] = 1 - df['Finish_Rate']\n",
        "\n",
        "        # 4. Circuit complexity indicator\n",
        "        df['Circuit_Complexity'] = df['Corners_in_Lap'] / (df['Len_Circuit_inkm'] + 0.001)\n",
        "        df['Avg_Speed_Per_Corner'] = df['Formula_Avg_Speed_kmh'] / (df['Corners_in_Lap'] + 1)\n",
        "\n",
        "        # 5. Weather/Track interactions\n",
        "        df['Humidity_x_Temp_Diff'] = df['Humidity_%'] * df['Temp_Difference']\n",
        "\n",
        "        # 6. Experience features\n",
        "        df['Experience_Level'] = np.log1p(df['starts'])  # Log transform for better scale\n",
        "        df['Win_to_Start_Ratio'] = df['wins'] / (df['starts'] + 1)\n",
        "\n",
        "        return df\n",
        "\n",
        "    def preprocess_data(self, df, is_training=True):\n",
        "        \"\"\"\n",
        "        Preprocess the dataset with advanced feature engineering.\n",
        "\n",
        "        Args:\n",
        "            df: Input dataframe\n",
        "            is_training: Whether this is training data\n",
        "\n",
        "        Returns:\n",
        "            Processed feature matrix\n",
        "        \"\"\"\n",
        "        print(f\"  Preprocessing data... (shape: {df.shape})\")\n",
        "        df = df.copy()\n",
        "\n",
        "        # Define categorical and numerical columns\n",
        "        categorical_cols = [\n",
        "            'Formula_category_x', 'Formula_Track_Condition', 'Tire_Compound',\n",
        "            'Penalty', 'Session', 'Formula_shortname', 'circuit_name',\n",
        "            'weather', 'track', 'air', 'ground'\n",
        "        ]\n",
        "\n",
        "        numerical_cols = [\n",
        "            'Len_Circuit_inkm', 'Laps', 'Start_Position', 'Formula_Avg_Speed_kmh',\n",
        "            'Humidity_%', 'Corners_in_Lap', 'Tire_Degradation_Factor_per_Lap',\n",
        "            'Pit_Stop_Duration_Seconds', 'Ambient_Temperature_Celsius',\n",
        "            'Track_Temperature_Celsius', 'starts', 'finishes', 'with_points',\n",
        "            'podiums', 'wins', 'race_year', 'position', 'points'\n",
        "        ]\n",
        "\n",
        "        # Handle missing values\n",
        "        print(\"  Handling missing values...\")\n",
        "        for col in numerical_cols:\n",
        "            if col in df.columns:\n",
        "                df[col] = df[col].fillna(df[col].median())\n",
        "\n",
        "        for col in categorical_cols:\n",
        "            if col in df.columns:\n",
        "                df[col] = df[col].fillna('Unknown')\n",
        "\n",
        "        # Encode categorical variables\n",
        "        print(\"  Encoding categorical variables...\")\n",
        "        for col in categorical_cols:\n",
        "            if col in df.columns:\n",
        "                if is_training:\n",
        "                    self.label_encoders[col] = LabelEncoder()\n",
        "                    df[col] = self.label_encoders[col].fit_transform(df[col].astype(str))\n",
        "                else:\n",
        "                    df[col] = df[col].astype(str).apply(\n",
        "                        lambda x: x if x in self.label_encoders[col].classes_\n",
        "                        else self.label_encoders[col].classes_[0]\n",
        "                    )\n",
        "                    df[col] = self.label_encoders[col].transform(df[col])\n",
        "\n",
        "        # Create advanced features\n",
        "        print(\"  Creating advanced engineered features...\")\n",
        "        df = self.create_advanced_features(df)\n",
        "\n",
        "        # Define all feature columns (original + engineered)\n",
        "        engineered_features = [\n",
        "            'Speed_to_Circuit_Ratio', 'Total_Distance', 'Temp_Difference',\n",
        "            'Win_Rate', 'Podium_Rate', 'Points_Rate', 'Finish_Rate',\n",
        "            'Speed_x_Corners', 'Circuit_x_Laps', 'Temp_x_Humidity',\n",
        "            'Degradation_x_Distance', 'PitStop_x_Laps',\n",
        "            'Speed_Squared', 'Corners_Squared', 'Temp_Squared',\n",
        "            'Success_Rate', 'Avg_Points_Per_Race', 'DNF_Rate',\n",
        "            'Circuit_Complexity', 'Avg_Speed_Per_Corner',\n",
        "            'Humidity_x_Temp_Diff', 'Experience_Level', 'Win_to_Start_Ratio'\n",
        "        ]\n",
        "\n",
        "        feature_cols = numerical_cols + categorical_cols + engineered_features\n",
        "        feature_cols = [col for col in feature_cols if col in df.columns]\n",
        "\n",
        "        if is_training:\n",
        "            self.feature_columns = feature_cols\n",
        "\n",
        "        print(f\"  Total features: {len(self.feature_columns)} ({len(engineered_features)} engineered)\")\n",
        "        return df[self.feature_columns]\n",
        "\n",
        "    def train(self, train_df, validation_df=None):\n",
        "        \"\"\"\n",
        "        Train the model with optional hyperparameter tuning.\n",
        "\n",
        "        Args:\n",
        "            train_df: Training dataframe\n",
        "            validation_df: Optional validation dataframe\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with training metrics\n",
        "        \"\"\"\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"TRAINING {self.model_type.upper().replace('_', ' ')} MODEL\")\n",
        "        if self.tune_hyperparameters:\n",
        "            print(\"WITH HYPERPARAMETER TUNING (Grid Search)\")\n",
        "        print(f\"{'='*70}\")\n",
        "\n",
        "        # Preprocess training data\n",
        "        print(\"\\n[1/4] Preprocessing training data...\")\n",
        "        X_train = self.preprocess_data(train_df, is_training=True)\n",
        "        y_train = train_df[self.target_column]\n",
        "\n",
        "        print(f\"  Training samples: {X_train.shape[0]:,}\")\n",
        "        print(f\"  Features: {X_train.shape[1]}\")\n",
        "        print(f\"  Target range: {y_train.min():.2f} - {y_train.max():.2f} seconds\")\n",
        "\n",
        "        # Scale features\n",
        "        print(\"\\n[2/4] Scaling features...\")\n",
        "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
        "\n",
        "        # Train model\n",
        "        print(\"\\n[3/4] Training model...\")\n",
        "        if self.tune_hyperparameters:\n",
        "            print(\"  Performing grid search (this will take longer)...\")\n",
        "            grid_search = GridSearchCV(\n",
        "                self.model,\n",
        "                self.param_grid,\n",
        "                cv=3,\n",
        "                scoring='neg_mean_squared_error',\n",
        "                n_jobs=-1,\n",
        "                verbose=2\n",
        "            )\n",
        "            grid_search.fit(X_train_scaled, y_train)\n",
        "            self.model = grid_search.best_estimator_\n",
        "\n",
        "            print(f\"\\n  ‚úÖ Best parameters found:\")\n",
        "            for param, value in grid_search.best_params_.items():\n",
        "                print(f\"     {param}: {value}\")\n",
        "        else:\n",
        "            self.model.fit(X_train_scaled, y_train)\n",
        "\n",
        "        # Evaluate\n",
        "        print(\"\\n[4/4] Evaluating model...\")\n",
        "        y_train_pred = self.model.predict(X_train_scaled)\n",
        "\n",
        "        metrics = {\n",
        "            'train_rmse': np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
        "        }\n",
        "\n",
        "        # Validation metrics if provided\n",
        "        if validation_df is not None:\n",
        "            print(\"\\n  Evaluating on validation set...\")\n",
        "            y_val_pred = self.predict(validation_df)\n",
        "            y_val = validation_df[self.target_column]\n",
        "            metrics['val_rmse'] = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
        "\n",
        "        # Print metrics\n",
        "        self._print_metrics(metrics)\n",
        "\n",
        "        # Feature importance\n",
        "        if hasattr(self.model, 'feature_importances_'):\n",
        "            importance_df = pd.DataFrame({\n",
        "                'feature': self.feature_columns,\n",
        "                'importance': self.model.feature_importances_\n",
        "            }).sort_values('importance', ascending=False)\n",
        "\n",
        "            print(f\"\\n{'='*70}\")\n",
        "            print(\"TOP 20 MOST IMPORTANT FEATURES\")\n",
        "            print(f\"{'='*70}\")\n",
        "            for idx, row in importance_df.head(20).iterrows():\n",
        "                marker = \"üÜï\" if any(x in row['feature'] for x in ['_x_', '_Squared', 'Success', 'DNF', 'Complexity', 'Experience']) else \"  \"\n",
        "                print(f\"{marker} {row['feature']:45s} {row['importance']:.4f}\")\n",
        "\n",
        "            self.feature_importance = importance_df\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    def evaluate(self, test_df):\n",
        "        \"\"\"Evaluate model on test dataset.\"\"\"\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(\"EVALUATING ON TEST DATASET\")\n",
        "        print(f\"{'='*70}\")\n",
        "\n",
        "        y_test_pred = self.predict(test_df)\n",
        "        y_test = test_df[self.target_column]\n",
        "\n",
        "        metrics = {\n",
        "            'test_rmse': np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
        "        }\n",
        "\n",
        "        self._print_metrics(metrics)\n",
        "\n",
        "        results_df = pd.DataFrame({\n",
        "            'Actual_Lap_Time': y_test,\n",
        "            'Predicted_Lap_Time': y_test_pred,\n",
        "            'Error': y_test - y_test_pred,\n",
        "            'Absolute_Error': np.abs(y_test - y_test_pred),\n",
        "            'Percentage_Error': np.abs((y_test - y_test_pred) / y_test) * 100\n",
        "        })\n",
        "\n",
        "        return metrics, results_df\n",
        "\n",
        "    def predict(self, df):\n",
        "        \"\"\"Make predictions on new data.\"\"\"\n",
        "        X = self.preprocess_data(df, is_training=False)\n",
        "        X_scaled = self.scaler.transform(X)\n",
        "        return self.model.predict(X_scaled)\n",
        "\n",
        "    def _print_metrics(self, metrics):\n",
        "        \"\"\"Print metrics in a formatted way.\"\"\"\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(\"MODEL PERFORMANCE METRICS\")\n",
        "        print(f\"{'='*70}\")\n",
        "\n",
        "        for key, value in metrics.items():\n",
        "            metric_name = key.replace('_', ' ').title()\n",
        "            print(f\"  {metric_name:25s}: {value:.3f} seconds\")\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# MAIN EXECUTION\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\"\"\n",
        "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "‚ïë    ADVANCED RACING LAP TIME PREDICTION WITH XGBOOST                 ‚ïë\n",
        "‚ïë    ‚Ä¢ Multiple Algorithms (RF, GB, XGBoost)                           ‚ïë\n",
        "‚ïë    ‚Ä¢ Hyperparameter Tuning                                           ‚ïë\n",
        "‚ïë    ‚Ä¢ Advanced Feature Engineering                                    ‚ïë\n",
        "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "\"\"\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"STEP 1: LOADING DATASETS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Load data\n",
        "train_path = 'train (1).csv'\n",
        "test_path = 'test.csv'\n",
        "\n",
        "print(f\"\\nLoading training data from: {train_path}\")\n",
        "train_df = pd.read_csv(train_path)\n",
        "print(f\"‚úì Training data loaded: {train_df.shape[0]:,} rows √ó {train_df.shape[1]} columns\")\n",
        "\n",
        "# Handle missing targets\n",
        "if 'Lap_Time_Seconds' in train_df.columns:\n",
        "    missing_targets = train_df['Lap_Time_Seconds'].isnull().sum()\n",
        "    if missing_targets > 0:\n",
        "        print(f\"‚ö†Ô∏è  Found {missing_targets:,} missing lap times in training data\")\n",
        "        print(f\"   Removing rows with missing target values...\")\n",
        "        train_df = train_df[train_df['Lap_Time_Seconds'].notna()].reset_index(drop=True)\n",
        "        print(f\"‚úì Cleaned training data: {train_df.shape[0]:,} rows remaining\")\n",
        "\n",
        "print(f\"\\nLoading test data from: {test_path}\")\n",
        "test_df = pd.read_csv(test_path)\n",
        "print(f\"‚úì Test data loaded: {test_df.shape[0]:,} rows √ó {test_df.shape[1]} columns\")\n",
        "\n",
        "has_test_labels = 'Lap_Time_Seconds' in test_df.columns\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 2: TRAIN MULTIPLE MODELS\n",
        "# ============================================================================\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"STEP 2: TRAINING MODELS\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "results_summary = {}\n",
        "\n",
        "# OPTION 1: Quick training (no hyperparameter tuning) - RECOMMENDED FOR LARGE DATASETS\n",
        "print(\"\\nüöÄ TRAINING MODE: Quick (No Hyperparameter Tuning)\")\n",
        "print(\"   Change tune_hyperparameters=True for grid search (much slower)\")\n",
        "\n",
        "models_to_train = [\n",
        "    ('random_forest', False),\n",
        "    ('gradient_boosting', False),\n",
        "    ('xgboost', False)\n",
        "]\n",
        "\n",
        "# Uncomment below to enable hyperparameter tuning (will take much longer!)\n",
        "# models_to_train = [\n",
        "#     ('xgboost', True)  # Just tune XGBoost for best results\n",
        "# ]\n",
        "\n",
        "for model_name, tune in models_to_train:\n",
        "    print(f\"\\n{'#'*70}\")\n",
        "    print(f\"# TRAINING: {model_name.upper().replace('_', ' ')}\")\n",
        "    print(f\"{'#'*70}\")\n",
        "\n",
        "    model = AdvancedLapTimePredictionModel(\n",
        "        model_type=model_name,\n",
        "        tune_hyperparameters=tune\n",
        "    )\n",
        "\n",
        "    train_metrics = model.train(train_df)\n",
        "    results_summary[model_name] = {\n",
        "        'model': model,\n",
        "        'train_rmse': train_metrics['train_rmse']\n",
        "    }\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 3: COMPARE MODELS\n",
        "# ============================================================================\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"MODEL COMPARISON SUMMARY\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Model': [name.replace('_', ' ').title() for name in results_summary.keys()],\n",
        "    'Training RMSE': [results_summary[name]['train_rmse'] for name in results_summary.keys()]\n",
        "}).sort_values('Training RMSE')\n",
        "\n",
        "print(\"\\n\" + comparison_df.to_string(index=False))\n",
        "\n",
        "best_model_name = comparison_df.iloc[0]['Model'].lower().replace(' ', '_')\n",
        "best_model = results_summary[best_model_name]['model']\n",
        "\n",
        "print(f\"\\nüèÜ BEST MODEL: {best_model_name.replace('_', ' ').title()}\")\n",
        "print(f\"   Training RMSE: {results_summary[best_model_name]['train_rmse']:.3f} seconds\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 4: GENERATE PREDICTIONS WITH BEST MODEL\n",
        "# ============================================================================\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"STEP 3: GENERATING PREDICTIONS WITH BEST MODEL\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "if has_test_labels:\n",
        "    test_metrics, results_df = best_model.evaluate(test_df)\n",
        "    has_evaluation = True\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è  Test dataset has no 'Lap_Time_Seconds' column\")\n",
        "    print(\"   Generating predictions only\\n\")\n",
        "\n",
        "    test_predictions = best_model.predict(test_df)\n",
        "    results_df = pd.DataFrame({\n",
        "        'Predicted_Lap_Time': test_predictions\n",
        "    })\n",
        "\n",
        "    if 'id' in test_df.columns:\n",
        "        results_df.insert(0, 'id', test_df['id'].values)\n",
        "\n",
        "    print(f\"‚úì Generated {len(test_predictions):,} predictions\")\n",
        "    print(f\"  Range: {test_predictions.min():.2f} - {test_predictions.max():.2f} seconds\")\n",
        "    print(f\"  Mean: {test_predictions.mean():.2f} seconds\")\n",
        "\n",
        "    has_evaluation = False\n",
        "    test_metrics = None\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 5: SAVE RESULTS\n",
        "# ============================================================================\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"STEP 4: SAVING PREDICTIONS\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "output_file = 'lap_time_predictions_advanced.csv'\n",
        "results_df.to_csv(output_file, index=False)\n",
        "print(f\"\\n‚úì Predictions saved to: {output_file}\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"SAMPLE PREDICTIONS (First 10 rows)\")\n",
        "print(f\"{'='*70}\")\n",
        "print(results_df.head(10).to_string(index=False))\n",
        "\n",
        "# ============================================================================\n",
        "# FINAL SUMMARY\n",
        "# ============================================================================\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"üéâ TRAINING COMPLETE!\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "print(f\"\\nüìä Best Model Performance:\")\n",
        "print(f\"   Model: {best_model_name.replace('_', ' ').title()}\")\n",
        "print(f\"   Training RMSE: {results_summary[best_model_name]['train_rmse']:.3f} seconds\")\n",
        "\n",
        "if has_evaluation and test_metrics:\n",
        "    print(f\"   Test RMSE: {test_metrics['test_rmse']:.3f} seconds\")\n",
        "\n",
        "    rmse = test_metrics['test_rmse']\n",
        "    if rmse < 5:\n",
        "        print(f\"\\n   ‚úÖ EXCELLENT: Very accurate predictions!\")\n",
        "    elif rmse < 6.5:\n",
        "        print(f\"\\n   ‚úÖ VERY GOOD: Strong improvement!\")\n",
        "    elif rmse < 7:\n",
        "        print(f\"\\n   ‚úÖ GOOD: Decent predictions\")\n",
        "    else:\n",
        "        print(f\"\\n   ‚ö†Ô∏è  MODERATE: Try hyperparameter tuning\")\n",
        "else:\n",
        "    print(f\"\\nüí° Training RMSE indicates expected performance\")\n",
        "\n",
        "print(f\"\\nüÜï Advanced Features Added:\")\n",
        "print(f\"   ‚Ä¢ Interaction features (Speed√óCorners, Temp√óHumidity, etc.)\")\n",
        "print(f\"   ‚Ä¢ Polynomial features (Speed¬≤, Corners¬≤, Temp¬≤)\")\n",
        "print(f\"   ‚Ä¢ Performance indicators (Success rate, DNF rate)\")\n",
        "print(f\"   ‚Ä¢ Circuit complexity metrics\")\n",
        "print(f\"   ‚Ä¢ Experience-based features\")\n",
        "\n",
        "print(f\"\\n‚úÖ Model ready for submission!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# RACING LAP TIME PREDICTION - ADVANCED MODEL WITH XGBOOST\n",
        "# ============================================================================\n",
        "# Features:\n",
        "# 1. Multiple algorithms: Random Forest, Gradient Boosting, XGBoost\n",
        "# 2. Hyperparameter tuning with GridSearchCV\n",
        "# 3. Advanced feature engineering (interactions, polynomials)\n",
        "# 4. Optimized for large datasets (700K+ rows)\n",
        "#\n",
        "# V2 Update:\n",
        "# - Saves prediction results to a separate CSV after EACH algorithm finishes.\n",
        "# - Saves the best model's predictions to 'lap_time_predictions_BEST.csv'.\n",
        "# ============================================================================\n",
        "\n",
        "# Install XGBoost\n",
        "!pip install xgboost --quiet\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, PolynomialFeatures\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import xgboost as xgb\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class AdvancedLapTimePredictionModel:\n",
        "    \"\"\"\n",
        "    Advanced ML model for predicting racing lap times.\n",
        "    Includes XGBoost, hyperparameter tuning, and feature engineering.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_type='xgboost', tune_hyperparameters=False):\n",
        "        \"\"\"\n",
        "        Initialize the model.\n",
        "\n",
        "        Args:\n",
        "            model_type: 'random_forest', 'gradient_boosting', or 'xgboost'\n",
        "            tune_hyperparameters: Whether to perform grid search\n",
        "        \"\"\"\n",
        "        self.model_type = model_type\n",
        "        self.tune_hyperparameters = tune_hyperparameters\n",
        "        self.scaler = StandardScaler()\n",
        "        self.label_encoders = {}\n",
        "        self.feature_columns = None\n",
        "        self.target_column = 'Lap_Time_Seconds'\n",
        "\n",
        "        # Initialize model based on type\n",
        "        if model_type == 'random_forest':\n",
        "            if tune_hyperparameters:\n",
        "                self.model = RandomForestRegressor(random_state=42, n_jobs=-1, verbose=0)\n",
        "                self.param_grid = {\n",
        "                    'n_estimators': [200 , 300],\n",
        "                    'max_depth': [15, 20, 25],\n",
        "                    'min_samples_split': [5, 10],\n",
        "                    'min_samples_leaf': [2, 4],\n",
        "                    'max_features': ['sqrt', 'log2']\n",
        "                }\n",
        "            else:\n",
        "                self.model = RandomForestRegressor(\n",
        "                    n_estimators=300,\n",
        "                    max_depth=25,\n",
        "                    min_samples_split=5,\n",
        "                    min_samples_leaf=2,\n",
        "                    max_features='sqrt',\n",
        "                    random_state=42,\n",
        "                    n_jobs=-1,\n",
        "                    verbose=1\n",
        "                )\n",
        "\n",
        "        elif model_type == 'gradient_boosting':\n",
        "            if tune_hyperparameters:\n",
        "                self.model = GradientBoostingRegressor(random_state=42, verbose=0)\n",
        "                self.param_grid = {\n",
        "                    'n_estimators': [200, 300],\n",
        "                    'max_depth': [5, 8, 10],\n",
        "                    'learning_rate': [0.05, 0.1, 0.15],\n",
        "                    'subsample': [0.7, 0.8, 0.9]\n",
        "                }\n",
        "            else:\n",
        "                self.model = GradientBoostingRegressor(\n",
        "                    n_estimators=200,\n",
        "                    max_depth=8,\n",
        "                    learning_rate=0.1,\n",
        "                    subsample=0.8,\n",
        "                    random_state=42,\n",
        "                    verbose=1\n",
        "                )\n",
        "\n",
        "        elif model_type == 'xgboost':\n",
        "            if tune_hyperparameters:\n",
        "                self.model = xgb.XGBRegressor(random_state=42, n_jobs=-1, verbosity=0)\n",
        "                self.param_grid = {\n",
        "                    'n_estimators': [200, 300, 400],\n",
        "                    'max_depth': [6, 8, 10],\n",
        "                    'learning_rate': [0.05, 0.1, 0.15],\n",
        "                    'subsample': [0.7, 0.8, 0.9],\n",
        "                    'colsample_bytree': [0.7, 0.8, 0.9]\n",
        "                }\n",
        "            else:\n",
        "                self.model = xgb.XGBRegressor(\n",
        "                    n_estimators=300,\n",
        "                    max_depth=8,\n",
        "                    learning_rate=0.1,\n",
        "                    subsample=0.8,\n",
        "                    colsample_bytree=0.8,\n",
        "                    random_state=42,\n",
        "                    n_jobs=-1,\n",
        "                    verbosity=1\n",
        "                )\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown model type: {model_type}\")\n",
        "\n",
        "    def create_advanced_features(self, df):\n",
        "        \"\"\"\n",
        "        Create advanced engineered features.\n",
        "\n",
        "        Args:\n",
        "            df: Input dataframe\n",
        "\n",
        "        Returns:\n",
        "            DataFrame with new features\n",
        "        \"\"\"\n",
        "        # Basic engineered features\n",
        "        df['Speed_to_Circuit_Ratio'] = df['Formula_Avg_Speed_kmh'] / (df['Len_Circuit_inkm'] + 0.001)\n",
        "        df['Total_Distance'] = df['Len_Circuit_inkm'] * df['Laps']\n",
        "        df['Temp_Difference'] = df['Track_Temperature_Celsius'] - df['Ambient_Temperature_Celsius']\n",
        "        df['Win_Rate'] = df['wins'] / (df['starts'] + 1)\n",
        "        df['Podium_Rate'] = df['podiums'] / (df['starts'] + 1)\n",
        "        df['Points_Rate'] = df['with_points'] / (df['starts'] + 1)\n",
        "        df['Finish_Rate'] = df['finishes'] / (df['starts'] + 1)\n",
        "\n",
        "        # ADVANCED FEATURES - NEW!\n",
        "\n",
        "        # 1. Interaction features (combining important factors)\n",
        "        df['Speed_x_Corners'] = df['Formula_Avg_Speed_kmh'] * df['Corners_in_Lap']\n",
        "        df['Circuit_x_Laps'] = df['Len_Circuit_inkm'] * df['Laps']\n",
        "        df['Temp_x_Humidity'] = df['Track_Temperature_Celsius'] * df['Humidity_%']\n",
        "        df['Degradation_x_Distance'] = df['Tire_Degradation_Factor_per_Lap'] * df['Total_Distance']\n",
        "        df['PitStop_x_Laps'] = df['Pit_Stop_Duration_Seconds'] * df['Laps']\n",
        "\n",
        "        # 2. Squared features (non-linear relationships)\n",
        "        df['Speed_Squared'] = df['Formula_Avg_Speed_kmh'] ** 2\n",
        "        df['Corners_Squared'] = df['Corners_in_Lap'] ** 2\n",
        "        df['Temp_Squared'] = df['Track_Temperature_Celsius'] ** 2\n",
        "\n",
        "        # 3. Performance indicators\n",
        "        df['Success_Rate'] = (df['wins'] + df['podiums']) / (df['starts'] + 1)\n",
        "        df['Avg_Points_Per_Race'] = df['points'] / (df['starts'] + 1)\n",
        "        df['DNF_Rate'] = 1 - df['Finish_Rate']\n",
        "\n",
        "        # 4. Circuit complexity indicator\n",
        "        df['Circuit_Complexity'] = df['Corners_in_Lap'] / (df['Len_Circuit_inkm'] + 0.001)\n",
        "        df['Avg_Speed_Per_Corner'] = df['Formula_Avg_Speed_kmh'] / (df['Corners_in_Lap'] + 1)\n",
        "\n",
        "        # 5. Weather/Track interactions\n",
        "        df['Humidity_x_Temp_Diff'] = df['Humidity_%'] * df['Temp_Difference']\n",
        "\n",
        "        # 6. Experience features\n",
        "        df['Experience_Level'] = np.log1p(df['starts'])  # Log transform for better scale\n",
        "        df['Win_to_Start_Ratio'] = df['wins'] / (df['starts'] + 1)\n",
        "\n",
        "        return df\n",
        "\n",
        "    def preprocess_data(self, df, is_training=True):\n",
        "        \"\"\"\n",
        "        Preprocess the dataset with advanced feature engineering.\n",
        "\n",
        "        Args:\n",
        "            df: Input dataframe\n",
        "            is_training: Whether this is training data\n",
        "\n",
        "        Returns:\n",
        "            Processed feature matrix\n",
        "        \"\"\"\n",
        "        print(f\"  Preprocessing data... (shape: {df.shape})\")\n",
        "        df = df.copy()\n",
        "\n",
        "        # Define categorical and numerical columns\n",
        "        categorical_cols = [\n",
        "            'Formula_category_x', 'Formula_Track_Condition', 'Tire_Compound',\n",
        "            'Penalty', 'Session', 'Formula_shortname', 'circuit_name',\n",
        "            'weather', 'track', 'air', 'ground'\n",
        "        ]\n",
        "\n",
        "        numerical_cols = [\n",
        "            'Len_Circuit_inkm', 'Laps', 'Start_Position', 'Formula_Avg_Speed_kmh',\n",
        "            'Humidity_%', 'Corners_in_Lap', 'Tire_Degradation_Factor_per_Lap',\n",
        "            'Pit_Stop_Duration_Seconds', 'Ambient_Temperature_Celsius',\n",
        "            'Track_Temperature_Celsius', 'starts', 'finishes', 'with_points',\n",
        "            'podiums', 'wins', 'race_year', 'position', 'points'\n",
        "        ]\n",
        "\n",
        "        # Handle missing values\n",
        "        print(\"  Handling missing values...\")\n",
        "        for col in numerical_cols:\n",
        "            if col in df.columns:\n",
        "                df[col] = df[col].fillna(df[col].median())\n",
        "\n",
        "        for col in categorical_cols:\n",
        "            if col in df.columns:\n",
        "                df[col] = df[col].fillna('Unknown')\n",
        "\n",
        "        # Encode categorical variables\n",
        "        print(\"  Encoding categorical variables...\")\n",
        "        for col in categorical_cols:\n",
        "            if col in df.columns:\n",
        "                if is_training:\n",
        "                    self.label_encoders[col] = LabelEncoder()\n",
        "                    df[col] = self.label_encoders[col].fit_transform(df[col].astype(str))\n",
        "                else:\n",
        "                    # Handle unseen labels during prediction\n",
        "                    df[col] = df[col].astype(str).apply(\n",
        "                        lambda x: x if x in self.label_encoders[col].classes_\n",
        "                        else self.label_encoders[col].classes_[0] # Default to first learned class\n",
        "                    )\n",
        "                    df[col] = self.label_encoders[col].transform(df[col])\n",
        "\n",
        "        # Create advanced features\n",
        "        print(\"  Creating advanced engineered features...\")\n",
        "        df = self.create_advanced_features(df)\n",
        "\n",
        "        # Define all feature columns (original + engineered)\n",
        "        engineered_features = [\n",
        "            'Speed_to_Circuit_Ratio', 'Total_Distance', 'Temp_Difference',\n",
        "            'Win_Rate', 'Podium_Rate', 'Points_Rate', 'Finish_Rate',\n",
        "            'Speed_x_Corners', 'Circuit_x_Laps', 'Temp_x_Humidity',\n",
        "            'Degradation_x_Distance', 'PitStop_x_Laps',\n",
        "            'Speed_Squared', 'Corners_Squared', 'Temp_Squared',\n",
        "            'Success_Rate', 'Avg_Points_Per_Race', 'DNF_Rate',\n",
        "            'Circuit_Complexity', 'Avg_Speed_Per_Corner',\n",
        "            'Humidity_x_Temp_Diff', 'Experience_Level', 'Win_to_Start_Ratio'\n",
        "        ]\n",
        "\n",
        "        feature_cols = numerical_cols + categorical_cols + engineered_features\n",
        "        # Ensure all columns exist in the dataframe\n",
        "        feature_cols = [col for col in feature_cols if col in df.columns]\n",
        "\n",
        "        if is_training:\n",
        "            self.feature_columns = feature_cols\n",
        "\n",
        "        # Ensure prediction df has same columns in same order as training\n",
        "        missing_in_pred = set(self.feature_columns) - set(df.columns)\n",
        "        for c in missing_in_pred:\n",
        "            df[c] = 0 # Should not happen if logic is correct, but safe fallback\n",
        "\n",
        "        df = df[self.feature_columns]\n",
        "\n",
        "        print(f\"  Total features: {len(self.feature_columns)} ({len(engineered_features)} engineered)\")\n",
        "        return df\n",
        "\n",
        "    def train(self, train_df, validation_df=None):\n",
        "        \"\"\"\n",
        "        Train the model with optional hyperparameter tuning.\n",
        "\n",
        "        Args:\n",
        "            train_df: Training dataframe\n",
        "            validation_df: Optional validation dataframe\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with training metrics\n",
        "        \"\"\"\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"TRAINING {self.model_type.upper().replace('_', ' ')} MODEL\")\n",
        "        if self.tune_hyperparameters:\n",
        "            print(\"WITH HYPERPARAMETER TUNING (Grid Search)\")\n",
        "        print(f\"{'='*70}\")\n",
        "\n",
        "        # Preprocess training data\n",
        "        print(\"\\n[1/4] Preprocessing training data...\")\n",
        "        X_train = self.preprocess_data(train_df, is_training=True)\n",
        "        y_train = train_df[self.target_column]\n",
        "\n",
        "        print(f\"  Training samples: {X_train.shape[0]:,}\")\n",
        "        print(f\"  Features: {X_train.shape[1]}\")\n",
        "        print(f\"  Target range: {y_train.min():.2f} - {y_train.max():.2f} seconds\")\n",
        "\n",
        "        # Scale features\n",
        "        print(\"\\n[2/4] Scaling features...\")\n",
        "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
        "\n",
        "        # Train model\n",
        "        print(\"\\n[3/4] Training model...\")\n",
        "        if self.tune_hyperparameters:\n",
        "            print(\"  Performing grid search (this will take longer)...\")\n",
        "            grid_search = GridSearchCV(\n",
        "                self.model,\n",
        "                self.param_grid,\n",
        "                cv=3,\n",
        "                scoring='neg_mean_squared_error',\n",
        "                n_jobs=-1,\n",
        "                verbose=2\n",
        "            )\n",
        "            grid_search.fit(X_train_scaled, y_train)\n",
        "            self.model = grid_search.best_estimator_\n",
        "\n",
        "            print(f\"\\n  ‚úÖ Best parameters found:\")\n",
        "            for param, value in grid_search.best_params_.items():\n",
        "                print(f\"      {param}: {value}\")\n",
        "        else:\n",
        "            self.model.fit(X_train_scaled, y_train)\n",
        "\n",
        "        # Evaluate\n",
        "        print(\"\\n[4/4] Evaluating model (on training data)...\")\n",
        "        y_train_pred = self.model.predict(X_train_scaled)\n",
        "\n",
        "        metrics = {\n",
        "            'train_rmse': np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
        "        }\n",
        "\n",
        "        # Validation metrics if provided\n",
        "        if validation_df is not None:\n",
        "            print(\"\\n  Evaluating on validation set...\")\n",
        "            y_val_pred = self.predict(validation_df)\n",
        "            y_val = validation_df[self.target_column]\n",
        "            metrics['val_rmse'] = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
        "\n",
        "        # Print metrics\n",
        "        self._print_metrics(metrics, \"Training Metrics\")\n",
        "\n",
        "        # Feature importance\n",
        "        if hasattr(self.model, 'feature_importances_'):\n",
        "            importance_df = pd.DataFrame({\n",
        "                'feature': self.feature_columns,\n",
        "                'importance': self.model.feature_importances_\n",
        "            }).sort_values('importance', ascending=False)\n",
        "\n",
        "            print(f\"\\n{'='*70}\")\n",
        "            print(\"TOP 20 MOST IMPORTANT FEATURES\")\n",
        "            print(f\"{'='*70}\")\n",
        "            for idx, row in importance_df.head(20).iterrows():\n",
        "                marker = \"üÜï\" if any(x in row['feature'] for x in ['_x_', '_Squared', 'Success', 'DNF', 'Complexity', 'Experience', 'Rate', 'Ratio']) else \"  \"\n",
        "                print(f\"{marker} {row['feature']:45s} {row['importance']:.4f}\")\n",
        "\n",
        "            self.feature_importance = importance_df\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    def evaluate(self, test_df):\n",
        "        \"\"\"Evaluate model on test dataset.\"\"\"\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"EVALUATING {self.model_type.upper()} ON TEST DATASET\")\n",
        "        print(f\"{'='*70}\")\n",
        "\n",
        "        y_test_pred = self.predict(test_df)\n",
        "        y_test = test_df[self.target_column]\n",
        "\n",
        "        metrics = {\n",
        "            'test_rmse': np.sqrt(mean_squared_error(y_test, y_test_pred)),\n",
        "            'test_mae': mean_absolute_error(y_test, y_test_pred),\n",
        "            'test_r2': r2_score(y_test, y_test_pred)\n",
        "        }\n",
        "\n",
        "        self._print_metrics(metrics, \"Test Metrics\")\n",
        "\n",
        "        results_df = pd.DataFrame({\n",
        "            'Actual_Lap_Time': y_test,\n",
        "            'Predicted_Lap_Time': y_test_pred,\n",
        "            'Error': y_test - y_test_pred,\n",
        "            'Absolute_Error': np.abs(y_test - y_test_pred),\n",
        "            'Percentage_Error': np.abs((y_test - y_test_pred) / y_test) * 100\n",
        "        })\n",
        "\n",
        "        if 'id' in test_df.columns:\n",
        "            results_df.insert(0, 'id', test_df['id'].values)\n",
        "\n",
        "        return metrics, results_df\n",
        "\n",
        "    def predict(self, df):\n",
        "        \"\"\"Make predictions on new data.\"\"\"\n",
        "        X = self.preprocess_data(df, is_training=False)\n",
        "        X_scaled = self.scaler.transform(X)\n",
        "        return self.model.predict(X_scaled)\n",
        "\n",
        "    def _print_metrics(self, metrics, title=\"MODEL PERFORMANCE METRICS\"):\n",
        "        \"\"\"Print metrics in a formatted way.\"\"\"\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(title)\n",
        "        print(f\"{'='*70}\")\n",
        "\n",
        "        for key, value in metrics.items():\n",
        "            metric_name = key.replace('_', ' ').title()\n",
        "            unit = \" seconds\" if 'rmse' in key or 'mae' in key else \"\"\n",
        "            print(f\"  {metric_name:25s}: {value:.4f}{unit}\")\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# MAIN EXECUTION\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\"\"\n",
        "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "‚ïë     ADVANCED RACING LAP TIME PREDICTION WITH XGBOOST                 ‚ïë\n",
        "‚ïë     ‚Ä¢ Multiple Algorithms (RF, GB, XGBoost)                          ‚ïë\n",
        "‚ïë     ‚Ä¢ Hyperparameter Tuning                                          ‚ïë\n",
        "‚ïë     ‚Ä¢ Advanced Feature Engineering                                   ‚ïë\n",
        "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "\"\"\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"STEP 1: LOADING DATASETS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Load data\n",
        "try:\n",
        "    train_path = 'train (1).csv'\n",
        "    train_df = pd.read_csv(train_path)\n",
        "    print(f\"‚úì Training data loaded from '{train_path}': {train_df.shape[0]:,} rows √ó {train_df.shape[1]} columns\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"‚ùå ERROR: Training file not found at '{train_path}'\")\n",
        "    exit()\n",
        "\n",
        "try:\n",
        "    test_path = 'test.csv'\n",
        "    test_df = pd.read_csv(test_path)\n",
        "    print(f\"‚úì Test data loaded from '{test_path}': {test_df.shape[0]:,} rows √ó {test_df.shape[1]} columns\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"‚ùå ERROR: Test file not found at '{test_path}'\")\n",
        "    exit()\n",
        "\n",
        "\n",
        "# Handle missing targets\n",
        "if 'Lap_Time_Seconds' in train_df.columns:\n",
        "    missing_targets = train_df['Lap_Time_Seconds'].isnull().sum()\n",
        "    if missing_targets > 0:\n",
        "        print(f\"‚ö†Ô∏è  Found {missing_targets:,} missing lap times in training data\")\n",
        "        print(f\"   Removing rows with missing target values...\")\n",
        "        train_df = train_df[train_df['Lap_Time_Seconds'].notna()].reset_index(drop=True)\n",
        "        print(f\"‚úì Cleaned training data: {train_df.shape[0]:,} rows remaining\")\n",
        "\n",
        "has_test_labels = 'Lap_Time_Seconds' in test_df.columns\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 2: TRAIN MULTIPLE MODELS & SAVE INDIVIDUAL PREDICTIONS\n",
        "# ============================================================================\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"STEP 2: TRAINING MODELS & SAVING PREDICTIONS\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "results_summary = {}\n",
        "all_results_dfs = {} # To store dataframes for final comparison\n",
        "\n",
        "# OPTION 1: Quick training (no hyperparameter tuning) - RECOMMENDED FOR LARGE DATASETS\n",
        "print(\"\\nüöÄ TRAINING MODE: Quick (No Hyperparameter Tuning)\")\n",
        "print(\"   Change tune_hyperparameters=True for grid search (much slower)\")\n",
        "\n",
        "models_to_train = [\n",
        "    ('random_forest', False),\n",
        "    ('gradient_boosting', False),\n",
        "    ('xgboost', False)\n",
        "]\n",
        "\n",
        "# Uncomment below to enable hyperparameter tuning (will take much longer!)\n",
        "# models_to_train = [\n",
        "#     ('xgboost', True)  # Just tune XGBoost for best results\n",
        "# ]\n",
        "\n",
        "for model_name, tune in models_to_train:\n",
        "    print(f\"\\n{'#'*70}\")\n",
        "    print(f\"# TRAINING: {model_name.upper().replace('_', ' ')}\")\n",
        "    print(f\"{'#'*70}\")\n",
        "\n",
        "    model = AdvancedLapTimePredictionModel(\n",
        "        model_type=model_name,\n",
        "        tune_hyperparameters=tune\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    train_metrics = model.train(train_df)\n",
        "    results_summary[model_name] = {\n",
        "        'model': model,\n",
        "        'train_rmse': train_metrics['train_rmse']\n",
        "    }\n",
        "\n",
        "    # --- PREDICT AND SAVE RESULTS FOR THIS MODEL ---\n",
        "    print(f\"\\n{'-'*70}\")\n",
        "    print(f\"GENERATING & SAVING PREDICTIONS for {model_name.upper()}\")\n",
        "    print(f\"{'-'*70}\")\n",
        "\n",
        "    model_results_df = None\n",
        "    if has_test_labels:\n",
        "        # If test set has labels, evaluate and get full results df\n",
        "        test_metrics, model_results_df = model.evaluate(test_df)\n",
        "        results_summary[model_name]['test_rmse'] = test_metrics['test_rmse']\n",
        "    else:\n",
        "        # If no test labels, just get predictions\n",
        "        print(\"\\n‚ö†Ô∏è  Test dataset has no 'Lap_Time_Seconds' column\")\n",
        "        print(\"   Generating predictions only\\n\")\n",
        "\n",
        "        test_predictions = model.predict(test_df)\n",
        "        model_results_df = pd.DataFrame({\n",
        "            'Predicted_Lap_Time': test_predictions\n",
        "        })\n",
        "\n",
        "        if 'id' in test_df.columns:\n",
        "            model_results_df.insert(0, 'id', test_df['id'].values)\n",
        "\n",
        "        print(f\"‚úì Generated {len(test_predictions):,} predictions\")\n",
        "        print(f\"  Range: {test_predictions.min():.2f} - {test_predictions.max():.2f} seconds\")\n",
        "        print(f\"  Mean: {test_predictions.mean():.2f} seconds\")\n",
        "\n",
        "    # Save the results for this specific model\n",
        "    output_file = f'lap_time_predictions_{model_name}.csv'\n",
        "    model_results_df.to_csv(output_file, index=False)\n",
        "    print(f\"\\n‚úì {model_name.upper()} predictions saved to: {output_file}\")\n",
        "\n",
        "    # Store dataframe for later\n",
        "    all_results_dfs[model_name] = model_results_df\n",
        "    # --- END OF PREDICTION BLOCK ---\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 3: COMPARE MODELS\n",
        "# ============================================================================\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"STEP 3: MODEL COMPARISON SUMMARY\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "# Add test RMSE to comparison if available\n",
        "comparison_data = {\n",
        "    'Model': [name.replace('_', ' ').title() for name in results_summary.keys()],\n",
        "    'Training RMSE': [results_summary[name]['train_rmse'] for name in results_summary.keys()]\n",
        "}\n",
        "\n",
        "sort_by = 'Training RMSE'\n",
        "if has_test_labels:\n",
        "    comparison_data['Test RMSE'] = [results_summary[name].get('test_rmse', np.nan) for name in results_summary.keys()]\n",
        "    sort_by = 'Test RMSE' # Sort by test RMSE if available\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_data).sort_values(sort_by)\n",
        "\n",
        "print(\"\\n\" + comparison_df.to_string(index=False))\n",
        "\n",
        "best_model_name = comparison_df.iloc[0]['Model'].lower().replace(' ', '_')\n",
        "best_model = results_summary[best_model_name]['model']\n",
        "best_results_df = all_results_dfs[best_model_name] # Get the already-generated results\n",
        "\n",
        "print(f\"\\nüèÜ BEST MODEL (based on {sort_by}): {best_model_name.replace('_', ' ').title()}\")\n",
        "print(f\"   Training RMSE: {results_summary[best_model_name]['train_rmse']:.3f} seconds\")\n",
        "if has_test_labels:\n",
        "    print(f\"   Test RMSE: {results_summary[best_model_name]['test_rmse']:.3f} seconds\")\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 4: SAVE BEST MODEL'S PREDICTIONS\n",
        "# ============================================================================\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"STEP 4: SAVING BEST MODEL'S PREDICTIONS\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "output_file = 'lap_time_predictions_BEST.csv'\n",
        "best_results_df.to_csv(output_file, index=False)\n",
        "print(f\"\\n‚úì Best model ({best_model_name}) predictions saved to: {output_file}\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"SAMPLE PREDICTIONS (First 10 rows from best model)\")\n",
        "print(f\"{'='*70}\")\n",
        "print(best_results_df.head(10).to_string(index=False))\n",
        "\n",
        "# ============================================================================\n",
        "# FINAL SUMMARY\n",
        "# ============================================================================\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"üéâ TRAINING COMPLETE!\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "print(f\"\\nüìä Best Model Performance:\")\n",
        "print(f\"   Model: {best_model_name.replace('_', ' ').title()}\")\n",
        "print(f\"   Training RMSE: {results_summary[best_model_name]['train_rmse']:.3f} seconds\")\n",
        "\n",
        "if has_test_labels and 'test_rmse' in results_summary[best_model_name]:\n",
        "    rmse = results_summary[best_model_name]['test_rmse']\n",
        "    print(f\"   Test RMSE: {rmse:.3f} seconds\")\n",
        "\n",
        "    if rmse < 5:\n",
        "        print(f\"\\n   ‚úÖ EXCELLENT: Very accurate predictions!\")\n",
        "    elif rmse < 6.5:\n",
        "        print(f\"\\n   ‚úÖ VERY GOOD: Strong improvement!\")\n",
        "    elif rmse < 7:\n",
        "        print(f\"\\n   ‚úÖ GOOD: Decent predictions\")\n",
        "    else:\n",
        "        print(f\"\\n   ‚ö†Ô∏è  MODERATE: Try hyperparameter tuning\")\n",
        "else:\n",
        "    print(f\"\\nüí° Training RMSE indicates expected performance (No test labels for scoring)\")\n",
        "\n",
        "print(f\"\\nüÜï Advanced Features Added:\")\n",
        "print(f\"   ‚Ä¢ Interaction features (Speed√óCorners, Temp√óHumidity, etc.)\")\n",
        "print(f\"   ‚Ä¢ Polynomial features (Speed¬≤, Corners¬≤, Temp¬≤)\")\n",
        "print(f\"   ‚Ä¢ Performance indicators (Success rate, DNF rate)\")\n",
        "print(f\"   ‚Ä¢ Circuit complexity metrics\")\n",
        "print(f\"   ‚Ä¢ Experience-based features\")\n",
        "\n",
        "print(f\"\\n‚úÖ All individual model CSVs saved:\")\n",
        "for model_name in results_summary.keys():\n",
        "    print(f\"   ‚Ä¢ lap_time_predictions_{model_name}.csv\")\n",
        "print(f\"   ‚Ä¢ lap_time_predictions_BEST.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAmMhw7UOuU4",
        "outputId": "f5255ed9-8a88-411d-d451-80e4cc3a13b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
            "‚ïë     ADVANCED RACING LAP TIME PREDICTION WITH XGBOOST                 ‚ïë\n",
            "‚ïë     ‚Ä¢ Multiple Algorithms (RF, GB, XGBoost)                          ‚ïë\n",
            "‚ïë     ‚Ä¢ Hyperparameter Tuning                                          ‚ïë\n",
            "‚ïë     ‚Ä¢ Advanced Feature Engineering                                   ‚ïë\n",
            "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
            "\n",
            "\n",
            "======================================================================\n",
            "STEP 1: LOADING DATASETS\n",
            "======================================================================\n",
            "‚úì Training data loaded from 'train (1).csv': 734,002 rows √ó 36 columns\n",
            "‚úì Test data loaded from 'test.csv': 314,573 rows √ó 35 columns\n",
            "\n",
            "======================================================================\n",
            "STEP 2: TRAINING MODELS & SAVING PREDICTIONS\n",
            "======================================================================\n",
            "\n",
            "üöÄ TRAINING MODE: Quick (No Hyperparameter Tuning)\n",
            "   Change tune_hyperparameters=True for grid search (much slower)\n",
            "\n",
            "######################################################################\n",
            "# TRAINING: RANDOM FOREST\n",
            "######################################################################\n",
            "\n",
            "======================================================================\n",
            "TRAINING RANDOM FOREST MODEL\n",
            "======================================================================\n",
            "\n",
            "[1/4] Preprocessing training data...\n",
            "  Preprocessing data... (shape: (734002, 36))\n",
            "  Handling missing values...\n",
            "  Encoding categorical variables...\n",
            "  Creating advanced engineered features...\n",
            "  Total features: 52 (23 engineered)\n",
            "  Training samples: 734,002\n",
            "  Features: 52\n",
            "  Target range: 70.00 - 110.00 seconds\n",
            "\n",
            "[2/4] Scaling features...\n",
            "\n",
            "[3/4] Training model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    4.7s finished\n",
            "[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[4/4] Evaluating model (on training data)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:    0.2s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "Training Metrics\n",
            "======================================================================\n",
            "  Train Rmse               : 5.2554 seconds\n",
            "\n",
            "======================================================================\n",
            "TOP 20 MOST IMPORTANT FEATURES\n",
            "======================================================================\n",
            "   Pit_Stop_Duration_Seconds                     0.0571\n",
            "   Temp_Difference                               0.0548\n",
            "   Ambient_Temperature_Celsius                   0.0518\n",
            "üÜï Temp_Squared                                  0.0514\n",
            "   Track_Temperature_Celsius                     0.0492\n",
            "   Tire_Degradation_Factor_per_Lap               0.0485\n",
            "   race_year                                     0.0422\n",
            "   circuit_name                                  0.0396\n",
            "   Formula_shortname                             0.0387\n",
            "   position                                      0.0352\n",
            "   Avg_Points_Per_Race                           0.0327\n",
            "üÜï Points_Rate                                   0.0312\n",
            "üÜï DNF_Rate                                      0.0304\n",
            "   Corners_in_Lap                                0.0301\n",
            "üÜï Corners_Squared                               0.0294\n",
            "   ground                                        0.0291\n",
            "üÜï Finish_Rate                                   0.0266\n",
            "   air                                           0.0266\n",
            "   finishes                                      0.0264\n",
            "   starts                                        0.0263\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "GENERATING & SAVING PREDICTIONS for RANDOM_FOREST\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "‚ö†Ô∏è  Test dataset has no 'Lap_Time_Seconds' column\n",
            "   Generating predictions only\n",
            "\n",
            "  Preprocessing data... (shape: (314573, 35))\n",
            "  Handling missing values...\n",
            "  Encoding categorical variables...\n",
            "  Creating advanced engineered features...\n",
            "  Total features: 52 (23 engineered)\n",
            "‚úì Generated 314,573 predictions\n",
            "  Range: 70.00 - 110.00 seconds\n",
            "  Mean: 89.99 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.\n",
            "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úì RANDOM_FOREST predictions saved to: lap_time_predictions_random_forest.csv\n",
            "\n",
            "######################################################################\n",
            "# TRAINING: GRADIENT BOOSTING\n",
            "######################################################################\n",
            "\n",
            "======================================================================\n",
            "TRAINING GRADIENT BOOSTING MODEL\n",
            "======================================================================\n",
            "\n",
            "[1/4] Preprocessing training data...\n",
            "  Preprocessing data... (shape: (734002, 36))\n",
            "  Handling missing values...\n",
            "  Encoding categorical variables...\n",
            "  Creating advanced engineered features...\n",
            "  Total features: 52 (23 engineered)\n",
            "  Training samples: 734,002\n",
            "  Features: 52\n",
            "  Target range: 70.00 - 110.00 seconds\n",
            "\n",
            "[2/4] Scaling features...\n",
            "\n",
            "[3/4] Training model...\n",
            "      Iter       Train Loss      OOB Improve   Remaining Time \n",
            "         1         132.2791           0.6240            2.03m\n",
            "         2         131.8241           0.5510            1.81m\n",
            "         3         131.1960           0.7022            1.58m\n",
            "         4         130.6625           0.3752            1.35m\n",
            "         5         130.2256           1.0183            1.13m\n",
            "         6         129.6156          -0.1676           54.16s\n",
            "         7         129.1597           0.6549           40.60s\n",
            "         8         128.6171           0.1204           27.05s\n",
            "         9         128.1267           0.7987           13.52s\n",
            "        10         128.0391           1.0180            0.00s\n",
            "\n",
            "[4/4] Evaluating model (on training data)...\n",
            "\n",
            "======================================================================\n",
            "Training Metrics\n",
            "======================================================================\n",
            "  Train Rmse               : 11.3102 seconds\n",
            "\n",
            "======================================================================\n",
            "TOP 20 MOST IMPORTANT FEATURES\n",
            "======================================================================\n",
            "   Temp_Difference                               0.0805\n",
            "   Pit_Stop_Duration_Seconds                     0.0797\n",
            "   Ambient_Temperature_Celsius                   0.0735\n",
            "   Tire_Degradation_Factor_per_Lap               0.0729\n",
            "   race_year                                     0.0605\n",
            "üÜï Points_Rate                                   0.0531\n",
            "   position                                      0.0472\n",
            "   Formula_shortname                             0.0471\n",
            "   Avg_Points_Per_Race                           0.0453\n",
            "   Track_Temperature_Celsius                     0.0419\n",
            "   circuit_name                                  0.0411\n",
            "üÜï Temp_Squared                                  0.0386\n",
            "üÜï Corners_Squared                               0.0323\n",
            "   ground                                        0.0282\n",
            "üÜï Finish_Rate                                   0.0274\n",
            "   Corners_in_Lap                                0.0243\n",
            "üÜï DNF_Rate                                      0.0239\n",
            "   finishes                                      0.0214\n",
            "   with_points                                   0.0208\n",
            "   air                                           0.0183\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "GENERATING & SAVING PREDICTIONS for GRADIENT_BOOSTING\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "‚ö†Ô∏è  Test dataset has no 'Lap_Time_Seconds' column\n",
            "   Generating predictions only\n",
            "\n",
            "  Preprocessing data... (shape: (314573, 35))\n",
            "  Handling missing values...\n",
            "  Encoding categorical variables...\n",
            "  Creating advanced engineered features...\n",
            "  Total features: 52 (23 engineered)\n",
            "‚úì Generated 314,573 predictions\n",
            "  Range: 83.35 - 97.34 seconds\n",
            "  Mean: 90.00 seconds\n",
            "\n",
            "‚úì GRADIENT_BOOSTING predictions saved to: lap_time_predictions_gradient_boosting.csv\n",
            "\n",
            "######################################################################\n",
            "# TRAINING: XGBOOST\n",
            "######################################################################\n",
            "\n",
            "======================================================================\n",
            "TRAINING XGBOOST MODEL\n",
            "======================================================================\n",
            "\n",
            "[1/4] Preprocessing training data...\n",
            "  Preprocessing data... (shape: (734002, 36))\n",
            "  Handling missing values...\n",
            "  Encoding categorical variables...\n",
            "  Creating advanced engineered features...\n",
            "  Total features: 52 (23 engineered)\n",
            "  Training samples: 734,002\n",
            "  Features: 52\n",
            "  Target range: 70.00 - 110.00 seconds\n",
            "\n",
            "[2/4] Scaling features...\n",
            "\n",
            "[3/4] Training model...\n",
            "\n",
            "[4/4] Evaluating model (on training data)...\n",
            "\n",
            "======================================================================\n",
            "Training Metrics\n",
            "======================================================================\n",
            "  Train Rmse               : 11.3028 seconds\n",
            "\n",
            "======================================================================\n",
            "TOP 20 MOST IMPORTANT FEATURES\n",
            "======================================================================\n",
            "üÜï Experience_Level                              0.0446\n",
            "üÜï Win_to_Start_Ratio                            0.0377\n",
            "   ground                                        0.0366\n",
            "üÜï DNF_Rate                                      0.0341\n",
            "   podiums                                       0.0327\n",
            "   finishes                                      0.0320\n",
            "   Avg_Points_Per_Race                           0.0320\n",
            "   points                                        0.0314\n",
            "üÜï PitStop_x_Laps                                0.0307\n",
            "üÜï Finish_Rate                                   0.0307\n",
            "üÜï Win_Rate                                      0.0306\n",
            "üÜï Points_Rate                                   0.0304\n",
            "üÜï Success_Rate                                  0.0302\n",
            "   circuit_name                                  0.0300\n",
            "   air                                           0.0294\n",
            "   Track_Temperature_Celsius                     0.0293\n",
            "   with_points                                   0.0291\n",
            "   Temp_Difference                               0.0290\n",
            "üÜï Temp_Squared                                  0.0287\n",
            "   track                                         0.0284\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "GENERATING & SAVING PREDICTIONS for XGBOOST\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "‚ö†Ô∏è  Test dataset has no 'Lap_Time_Seconds' column\n",
            "   Generating predictions only\n",
            "\n",
            "  Preprocessing data... (shape: (314573, 35))\n",
            "  Handling missing values...\n",
            "  Encoding categorical variables...\n",
            "  Creating advanced engineered features...\n",
            "  Total features: 52 (23 engineered)\n",
            "‚úì Generated 314,573 predictions\n",
            "  Range: 83.55 - 95.96 seconds\n",
            "  Mean: 90.00 seconds\n",
            "\n",
            "‚úì XGBOOST predictions saved to: lap_time_predictions_xgboost.csv\n",
            "\n",
            "======================================================================\n",
            "STEP 3: MODEL COMPARISON SUMMARY\n",
            "======================================================================\n",
            "\n",
            "            Model  Training RMSE\n",
            "    Random Forest       5.255397\n",
            "          Xgboost      11.302763\n",
            "Gradient Boosting      11.310155\n",
            "\n",
            "üèÜ BEST MODEL (based on Training RMSE): Random Forest\n",
            "   Training RMSE: 5.255 seconds\n",
            "\n",
            "======================================================================\n",
            "STEP 4: SAVING BEST MODEL'S PREDICTIONS\n",
            "======================================================================\n",
            "\n",
            "‚úì Best model (random_forest) predictions saved to: lap_time_predictions_BEST.csv\n",
            "\n",
            "======================================================================\n",
            "SAMPLE PREDICTIONS (First 10 rows from best model)\n",
            "======================================================================\n",
            "    id  Predicted_Lap_Time\n",
            "781975           96.734771\n",
            "937738           85.012687\n",
            "907829           88.748128\n",
            "784629           91.859226\n",
            "662461           95.243292\n",
            "280140           90.193545\n",
            "355573           96.276851\n",
            "749980           96.265245\n",
            "374754           82.008061\n",
            " 17328           93.178329\n",
            "\n",
            "======================================================================\n",
            "üéâ TRAINING COMPLETE!\n",
            "======================================================================\n",
            "\n",
            "üìä Best Model Performance:\n",
            "   Model: Random Forest\n",
            "   Training RMSE: 5.255 seconds\n",
            "\n",
            "üí° Training RMSE indicates expected performance (No test labels for scoring)\n",
            "\n",
            "üÜï Advanced Features Added:\n",
            "   ‚Ä¢ Interaction features (Speed√óCorners, Temp√óHumidity, etc.)\n",
            "   ‚Ä¢ Polynomial features (Speed¬≤, Corners¬≤, Temp¬≤)\n",
            "   ‚Ä¢ Performance indicators (Success rate, DNF rate)\n",
            "   ‚Ä¢ Circuit complexity metrics\n",
            "   ‚Ä¢ Experience-based features\n",
            "\n",
            "‚úÖ All individual model CSVs saved:\n",
            "   ‚Ä¢ lap_time_predictions_random_forest.csv\n",
            "   ‚Ä¢ lap_time_predictions_gradient_boosting.csv\n",
            "   ‚Ä¢ lap_time_predictions_xgboost.csv\n",
            "   ‚Ä¢ lap_time_predictions_BEST.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zgogLg9X70NL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# FEATURE-SPECIFIC MODELS - SPECIALIZED ENSEMBLES\n",
        "# ============================================================================\n",
        "# Strategy: Train separate models for different data segments\n",
        "# 1. Formula-specific models (Formula1, Formula2, Formula3)\n",
        "# 2. Condition-specific models (Wet vs Dry)\n",
        "# 3. Circuit-complexity models (Simple vs Technical tracks)\n",
        "# 4. Combine all with intelligent routing\n",
        "# Expected: 0.29 ‚Üí 0.18-0.21 (17-31% improvement)\n",
        "# ============================================================================\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import KFold\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from catboost import CatBoostRegressor\n",
        "from category_encoders import TargetEncoder\n",
        "import time\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ============================================================================\n",
        "# TIMER UTILITY\n",
        "# ============================================================================\n",
        "class Timer:\n",
        "    \"\"\"Track time for each step.\"\"\"\n",
        "    def __init__(self):\n",
        "        self.start_time = None\n",
        "        self.step_times = {}\n",
        "\n",
        "    def start(self, step_name):\n",
        "        self.start_time = time.time()\n",
        "        print(f\"\\n‚è±Ô∏è  Starting: {step_name}\")\n",
        "        print(f\"   Time: {datetime.now().strftime('%H:%M:%S')}\")\n",
        "\n",
        "    def end(self, step_name):\n",
        "        elapsed = time.time() - self.start_time\n",
        "        self.step_times[step_name] = elapsed\n",
        "        print(f\"‚úÖ Completed: {step_name}\")\n",
        "        print(f\"   Duration: {timedelta(seconds=int(elapsed))}\")\n",
        "        return elapsed\n",
        "\n",
        "    def summary(self):\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(\"TIME SUMMARY\")\n",
        "        print(f\"{'='*70}\")\n",
        "        total = 0\n",
        "        for step, duration in self.step_times.items():\n",
        "            print(f\"  {step:50s} {timedelta(seconds=int(duration))}\")\n",
        "            total += duration\n",
        "        print(f\"  {'‚îÄ'*70}\")\n",
        "        print(f\"  {'TOTAL':50s} {timedelta(seconds=int(total))}\")\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# FEATURE ENGINEERING\n",
        "# ============================================================================\n",
        "class FeatureEngineer:\n",
        "    \"\"\"Feature engineering with aggregations and target encoding.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.target_encoders = {}\n",
        "        self.aggregations = {}\n",
        "\n",
        "    def fit(self, df, target_col='Lap_Time_Seconds'):\n",
        "        \"\"\"Learn aggregations from training data.\"\"\"\n",
        "        print(\"    Learning aggregations...\")\n",
        "\n",
        "        # Circuit aggregations\n",
        "        circuit_aggs = df.groupby('circuit_name').agg({\n",
        "            target_col: ['mean', 'std', 'min', 'max', 'median'],\n",
        "            'Formula_Avg_Speed_kmh': ['mean', 'max'],\n",
        "            'Corners_in_Lap': 'mean',\n",
        "            'Track_Temperature_Celsius': 'mean',\n",
        "            'Humidity_%': 'mean'\n",
        "        })\n",
        "        circuit_aggs.columns = ['_'.join(col).strip() for col in circuit_aggs.columns]\n",
        "        circuit_aggs = circuit_aggs.add_prefix('circuit_')\n",
        "        self.aggregations['circuit'] = circuit_aggs.reset_index()\n",
        "\n",
        "        # Driver aggregations\n",
        "        if 'Rider_ID' in df.columns:\n",
        "            driver_aggs = df.groupby('Rider_ID').agg({\n",
        "                target_col: ['mean', 'std', 'min'],\n",
        "                'wins': 'sum',\n",
        "                'podiums': 'sum',\n",
        "                'starts': 'sum'\n",
        "            })\n",
        "            driver_aggs.columns = ['_'.join(col).strip() for col in driver_aggs.columns]\n",
        "            driver_aggs = driver_aggs.add_prefix('driver_')\n",
        "            self.aggregations['driver'] = driver_aggs.reset_index()\n",
        "\n",
        "        # Driver √ó Circuit\n",
        "        if 'Rider_ID' in df.columns:\n",
        "            driver_circuit = df.groupby(['Rider_ID', 'circuit_name']).agg({\n",
        "                target_col: ['mean', 'count'],\n",
        "                'wins': 'sum'\n",
        "            })\n",
        "            driver_circuit.columns = ['_'.join(col).strip() for col in driver_circuit.columns]\n",
        "            driver_circuit = driver_circuit.add_prefix('dc_')\n",
        "            self.aggregations['driver_circuit'] = driver_circuit.reset_index()\n",
        "\n",
        "        # Target encoding\n",
        "        print(\"    Learning target encodings...\")\n",
        "        for col in ['circuit_name', 'Rider_ID', 'Formula_shortname']:\n",
        "            if col in df.columns:\n",
        "                self.target_encoders[col] = TargetEncoder(smoothing=10)\n",
        "                self.target_encoders[col].fit(df[[col]], df[target_col])\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, df):\n",
        "        \"\"\"Apply learned transformations.\"\"\"\n",
        "        df = df.copy()\n",
        "\n",
        "        # Merge aggregations\n",
        "        df = df.merge(self.aggregations['circuit'], on='circuit_name', how='left')\n",
        "\n",
        "        if 'driver' in self.aggregations and 'Rider_ID' in df.columns:\n",
        "            df = df.merge(self.aggregations['driver'], on='Rider_ID', how='left')\n",
        "\n",
        "        if 'driver_circuit' in self.aggregations and 'Rider_ID' in df.columns:\n",
        "            df = df.merge(self.aggregations['driver_circuit'],\n",
        "                         on=['Rider_ID', 'circuit_name'], how='left')\n",
        "\n",
        "        # Apply target encoding\n",
        "        for col, encoder in self.target_encoders.items():\n",
        "            if col in df.columns:\n",
        "                df[f'{col}_te'] = encoder.transform(df[[col]])\n",
        "\n",
        "        # Engineered features\n",
        "        df['Speed_to_Circuit_Ratio'] = df['Formula_Avg_Speed_kmh'] / (df['Len_Circuit_inkm'] + 0.001)\n",
        "        df['Total_Distance'] = df['Len_Circuit_inkm'] * df['Laps']\n",
        "        df['Temp_Difference'] = df['Track_Temperature_Celsius'] - df['Ambient_Temperature_Celsius']\n",
        "\n",
        "        df['Win_Rate'] = df['wins'] / (df['starts'] + 1)\n",
        "        df['Podium_Rate'] = df['podiums'] / (df['starts'] + 1)\n",
        "        df['Points_Rate'] = df['with_points'] / (df['starts'] + 1)\n",
        "        df['Finish_Rate'] = df['finishes'] / (df['starts'] + 1)\n",
        "\n",
        "        df['Speed_x_Corners'] = df['Formula_Avg_Speed_kmh'] * df['Corners_in_Lap']\n",
        "        df['Degradation_x_Distance'] = df['Tire_Degradation_Factor_per_Lap'] * df['Total_Distance']\n",
        "        df['Circuit_Complexity'] = df['Corners_in_Lap'] / (df['Len_Circuit_inkm'] + 0.001)\n",
        "\n",
        "        df['Experience_Level'] = np.log1p(df['starts'])\n",
        "        df['Starting_Advantage'] = 1 / (df['Start_Position'] + 1)\n",
        "        df['Position_Change'] = df['Start_Position'] - df['position']\n",
        "\n",
        "        # Comparison with aggregations\n",
        "        if 'circuit_Lap_Time_Seconds_mean' in df.columns:\n",
        "            df['Speed_vs_Circuit_Avg'] = df['Formula_Avg_Speed_kmh'] - df.get('circuit_Formula_Avg_Speed_kmh_mean', 0)\n",
        "\n",
        "        if 'driver_Lap_Time_Seconds_mean' in df.columns:\n",
        "            df['Driver_Performance_vs_Circuit'] = (df.get('driver_Lap_Time_Seconds_mean', 90) /\n",
        "                                                   (df.get('circuit_Lap_Time_Seconds_mean', 90) + 0.001))\n",
        "\n",
        "        # Fill NaN\n",
        "        for col in df.columns:\n",
        "            if df[col].dtype in ['float64', 'int64']:\n",
        "                df[col] = df[col].fillna(df[col].median() if df[col].notna().any() else 0)\n",
        "\n",
        "        return df\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# SPECIALIZED MODEL TRAINER\n",
        "# ============================================================================\n",
        "class SpecializedModelTrainer:\n",
        "    \"\"\"Train models for specific data segments.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.models = {}\n",
        "        self.feature_engineers = {}\n",
        "        self.scalers = {}\n",
        "        self.feature_cols = {}\n",
        "\n",
        "    def train_segment(self, train_df, segment_name, segment_filter=None):\n",
        "        \"\"\"Train a model for a specific data segment.\"\"\"\n",
        "        print(f\"\\n    Training {segment_name} model...\")\n",
        "\n",
        "        # Filter data if needed\n",
        "        if segment_filter is not None:\n",
        "            segment_data = train_df[segment_filter].copy()\n",
        "        else:\n",
        "            segment_data = train_df.copy()\n",
        "\n",
        "        print(f\"      Segment size: {len(segment_data):,} rows\")\n",
        "\n",
        "        if len(segment_data) < 100:\n",
        "            print(f\"      ‚ö†Ô∏è  Too few samples, skipping...\")\n",
        "            return None\n",
        "\n",
        "        # Feature engineering\n",
        "        fe = FeatureEngineer()\n",
        "        fe.fit(segment_data)\n",
        "        X_processed = fe.transform(segment_data)\n",
        "\n",
        "        # Select features\n",
        "        feature_cols = [c for c in X_processed.columns\n",
        "                       if c not in ['Lap_Time_Seconds', 'Rider_ID', 'id', 'Unique ID']]\n",
        "        feature_cols = [c for c in feature_cols if X_processed[c].dtype in ['int64', 'float64']]\n",
        "\n",
        "        X = X_processed[feature_cols].fillna(0)\n",
        "        y = segment_data['Lap_Time_Seconds'].values\n",
        "\n",
        "        # Scale\n",
        "        scaler = StandardScaler()\n",
        "        X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "        # Train ensemble of 3 models\n",
        "        models = {}\n",
        "\n",
        "        # XGBoost\n",
        "        xgb_model = xgb.XGBRegressor(\n",
        "            n_estimators=3000,\n",
        "            max_depth=10,\n",
        "            learning_rate=0.05,\n",
        "            subsample=0.8,\n",
        "            colsample_bytree=0.8,\n",
        "            tree_method='gpu_hist',  # GPU acceleration\n",
        "            gpu_id=0,\n",
        "            random_state=42,\n",
        "            verbosity=0\n",
        "        )\n",
        "        xgb_model.fit(X_scaled, y)\n",
        "        models['xgb'] = xgb_model\n",
        "\n",
        "        # LightGBM\n",
        "        lgb_model = lgb.LGBMRegressor(\n",
        "            n_estimators=3000,\n",
        "            max_depth=10,\n",
        "            learning_rate=0.05,\n",
        "            num_leaves=127,\n",
        "            subsample=0.8,\n",
        "            device='gpu',  # GPU acceleration\n",
        "            random_state=42,\n",
        "            verbose=-1\n",
        "        )\n",
        "        lgb_model.fit(X_scaled, y)\n",
        "        models['lgb'] = lgb_model\n",
        "\n",
        "        # CatBoost\n",
        "        cat_model = CatBoostRegressor(\n",
        "            iterations=2000,\n",
        "            depth=8,\n",
        "            learning_rate=0.05,\n",
        "            task_type='GPU',  # GPU acceleration\n",
        "            random_seed=42,\n",
        "            verbose=0\n",
        "        )\n",
        "        cat_model.fit(X_scaled, y)\n",
        "        models['cat'] = cat_model\n",
        "\n",
        "        # Calculate segment RMSE\n",
        "        preds_xgb = xgb_model.predict(X_scaled)\n",
        "        preds_lgb = lgb_model.predict(X_scaled)\n",
        "        preds_cat = cat_model.predict(X_scaled)\n",
        "        preds_avg = (preds_xgb + preds_lgb + preds_cat) / 3\n",
        "\n",
        "        segment_rmse = np.sqrt(mean_squared_error(y, preds_avg))\n",
        "        print(f\"      ‚úÖ Segment RMSE: {segment_rmse:.4f}\")\n",
        "\n",
        "        # Store everything\n",
        "        self.models[segment_name] = models\n",
        "        self.feature_engineers[segment_name] = fe\n",
        "        self.scalers[segment_name] = scaler\n",
        "        self.feature_cols[segment_name] = feature_cols\n",
        "\n",
        "        return segment_rmse\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# FEATURE-SPECIFIC ENSEMBLE\n",
        "# ============================================================================\n",
        "class FeatureSpecificEnsemble:\n",
        "    \"\"\"Main ensemble with specialized models.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.trainers = {}\n",
        "        self.timer = Timer()\n",
        "\n",
        "    def train(self, train_df):\n",
        "        \"\"\"Train all specialized models.\"\"\"\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(\"FEATURE-SPECIFIC ENSEMBLE TRAINING\")\n",
        "        print(f\"{'='*70}\")\n",
        "        print(f\"Dataset: {len(train_df):,} rows\")\n",
        "\n",
        "        total_start = time.time()\n",
        "\n",
        "        # ========== FORMULA-SPECIFIC MODELS ==========\n",
        "        self.timer.start(\"Formula-Specific Models\")\n",
        "\n",
        "        self.trainers['formula'] = SpecializedModelTrainer()\n",
        "\n",
        "        # Formula 1\n",
        "        formula1_filter = train_df['Formula_category_x'] == 'Formula1'\n",
        "        self.trainers['formula'].train_segment(train_df, 'Formula1', formula1_filter)\n",
        "\n",
        "        # Formula 2\n",
        "        formula2_filter = train_df['Formula_category_x'] == 'Formula2'\n",
        "        self.trainers['formula'].train_segment(train_df, 'Formula2', formula2_filter)\n",
        "\n",
        "        # Formula 3\n",
        "        formula3_filter = train_df['Formula_category_x'] == 'Formula3'\n",
        "        self.trainers['formula'].train_segment(train_df, 'Formula3', formula3_filter)\n",
        "\n",
        "        self.timer.end(\"Formula-Specific Models\")\n",
        "\n",
        "        # ========== CONDITION-SPECIFIC MODELS ==========\n",
        "        self.timer.start(\"Condition-Specific Models\")\n",
        "\n",
        "        self.trainers['condition'] = SpecializedModelTrainer()\n",
        "\n",
        "        # Wet conditions\n",
        "        wet_filter = train_df['Formula_Track_Condition'] == 'Wet'\n",
        "        self.trainers['condition'].train_segment(train_df, 'Wet', wet_filter)\n",
        "\n",
        "        # Dry conditions\n",
        "        dry_filter = train_df['Formula_Track_Condition'] == 'Dry'\n",
        "        self.trainers['condition'].train_segment(train_df, 'Dry', dry_filter)\n",
        "\n",
        "        self.timer.end(\"Condition-Specific Models\")\n",
        "\n",
        "        # ========== CIRCUIT COMPLEXITY MODELS ==========\n",
        "        self.timer.start(\"Circuit-Complexity Models\")\n",
        "\n",
        "        self.trainers['complexity'] = SpecializedModelTrainer()\n",
        "\n",
        "        # Simple circuits (<15 corners)\n",
        "        simple_filter = train_df['Corners_in_Lap'] < 15\n",
        "        self.trainers['complexity'].train_segment(train_df, 'Simple_Circuit', simple_filter)\n",
        "\n",
        "        # Technical circuits (‚â•15 corners)\n",
        "        technical_filter = train_df['Corners_in_Lap'] >= 15\n",
        "        self.trainers['complexity'].train_segment(train_df, 'Technical_Circuit', technical_filter)\n",
        "\n",
        "        self.timer.end(\"Circuit-Complexity Models\")\n",
        "\n",
        "        # ========== SPEED CATEGORY MODELS ==========\n",
        "        self.timer.start(\"Speed-Category Models\")\n",
        "\n",
        "        self.trainers['speed'] = SpecializedModelTrainer()\n",
        "\n",
        "        speed_median = train_df['Formula_Avg_Speed_kmh'].median()\n",
        "\n",
        "        # High-speed races\n",
        "        high_speed_filter = train_df['Formula_Avg_Speed_kmh'] >= speed_median\n",
        "        self.trainers['speed'].train_segment(train_df, 'High_Speed', high_speed_filter)\n",
        "\n",
        "        # Low-speed races\n",
        "        low_speed_filter = train_df['Formula_Avg_Speed_kmh'] < speed_median\n",
        "        self.trainers['speed'].train_segment(train_df, 'Low_Speed', low_speed_filter)\n",
        "\n",
        "        self.timer.end(\"Speed-Category Models\")\n",
        "\n",
        "        # ========== GENERAL FALLBACK MODEL ==========\n",
        "        self.timer.start(\"General Fallback Model\")\n",
        "\n",
        "        self.trainers['general'] = SpecializedModelTrainer()\n",
        "        self.trainers['general'].train_segment(train_df, 'General', None)\n",
        "\n",
        "        self.timer.end(\"General Fallback Model\")\n",
        "\n",
        "        # ========== CALCULATE OVERALL CV SCORE ==========\n",
        "        self.timer.start(\"Cross-Validation Score\")\n",
        "\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(\"CALCULATING OVERALL CV SCORE\")\n",
        "        print(f\"{'='*70}\")\n",
        "\n",
        "        all_preds = self.predict(train_df)\n",
        "        overall_rmse = np.sqrt(mean_squared_error(train_df['Lap_Time_Seconds'], all_preds))\n",
        "\n",
        "        print(f\"\\nüéØ OVERALL CV RMSE: {overall_rmse:.4f}\")\n",
        "\n",
        "        self.timer.end(\"Cross-Validation Score\")\n",
        "\n",
        "        # Summary\n",
        "        total_time = time.time() - total_start\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(\"TRAINING COMPLETE!\")\n",
        "        print(f\"{'='*70}\")\n",
        "        print(f\"Total training time: {timedelta(seconds=int(total_time))}\")\n",
        "        print(f\"Final RMSE: {overall_rmse:.4f}\")\n",
        "\n",
        "        if overall_rmse < 0.20:\n",
        "            print(f\"‚úÖ TARGET ACHIEVED! RMSE < 0.20!\")\n",
        "        elif overall_rmse < 0.25:\n",
        "            print(f\"üìà Very close! Almost there!\")\n",
        "        else:\n",
        "            print(f\"‚ö†Ô∏è  Keep optimizing...\")\n",
        "\n",
        "        return overall_rmse\n",
        "\n",
        "    def predict(self, test_df):\n",
        "        \"\"\"Generate predictions using specialized models.\"\"\"\n",
        "        predictions = np.zeros(len(test_df))\n",
        "\n",
        "        # Route each row to appropriate models and average\n",
        "        for idx in range(len(test_df)):\n",
        "            row_preds = []\n",
        "\n",
        "            # Formula-specific\n",
        "            formula = test_df.iloc[idx]['Formula_category_x']\n",
        "            if formula in self.trainers['formula'].models:\n",
        "                row_preds.append(self._predict_row(test_df.iloc[[idx]], 'formula', formula))\n",
        "\n",
        "            # Condition-specific\n",
        "            condition = test_df.iloc[idx]['Formula_Track_Condition']\n",
        "            if condition in self.trainers['condition'].models:\n",
        "                row_preds.append(self._predict_row(test_df.iloc[[idx]], 'condition', condition))\n",
        "\n",
        "            # Complexity-specific\n",
        "            corners = test_df.iloc[idx]['Corners_in_Lap']\n",
        "            complexity = 'Simple_Circuit' if corners < 15 else 'Technical_Circuit'\n",
        "            if complexity in self.trainers['complexity'].models:\n",
        "                row_preds.append(self._predict_row(test_df.iloc[[idx]], 'complexity', complexity))\n",
        "\n",
        "            # Speed-specific\n",
        "            speed_median = 250  # Approximate, should be calculated from train\n",
        "            speed = test_df.iloc[idx]['Formula_Avg_Speed_kmh']\n",
        "            speed_cat = 'High_Speed' if speed >= speed_median else 'Low_Speed'\n",
        "            if speed_cat in self.trainers['speed'].models:\n",
        "                row_preds.append(self._predict_row(test_df.iloc[[idx]], 'speed', speed_cat))\n",
        "\n",
        "            # General fallback\n",
        "            if 'General' in self.trainers['general'].models:\n",
        "                row_preds.append(self._predict_row(test_df.iloc[[idx]], 'general', 'General'))\n",
        "\n",
        "            # Average all applicable predictions\n",
        "            predictions[idx] = np.mean(row_preds) if row_preds else 90.0  # fallback value\n",
        "\n",
        "        return predictions\n",
        "\n",
        "    def _predict_row(self, row_df, trainer_key, model_key):\n",
        "        \"\"\"Predict for a single row using a specific model.\"\"\"\n",
        "        trainer = self.trainers[trainer_key]\n",
        "\n",
        "        # Transform features\n",
        "        X_proc = trainer.feature_engineers[model_key].transform(row_df)\n",
        "        X = X_proc[trainer.feature_cols[model_key]].fillna(0)\n",
        "        X_scaled = trainer.scalers[model_key].transform(X)\n",
        "\n",
        "        # Get predictions from all 3 models\n",
        "        pred_xgb = trainer.models[model_key]['xgb'].predict(X_scaled)[0]\n",
        "        pred_lgb = trainer.models[model_key]['lgb'].predict(X_scaled)[0]\n",
        "        pred_cat = trainer.models[model_key]['cat'].predict(X_scaled)[0]\n",
        "\n",
        "        return (pred_xgb + pred_lgb + pred_cat) / 3\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# MAIN EXECUTION\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\"\"\n",
        "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "‚ïë          FEATURE-SPECIFIC MODELS ENSEMBLE                            ‚ïë\n",
        "‚ïë          ‚Ä¢ Formula-specific (F1, F2, F3)                             ‚ïë\n",
        "‚ïë          ‚Ä¢ Condition-specific (Wet, Dry)                             ‚ïë\n",
        "‚ïë          ‚Ä¢ Circuit-complexity (Simple, Technical)                    ‚ïë\n",
        "‚ïë          ‚Ä¢ Speed-category (High, Low)                                ‚ïë\n",
        "‚ïë          ‚Ä¢ General fallback model                                    ‚ïë\n",
        "‚ïë          ‚Ä¢ GPU-Accelerated (XGBoost + LightGBM + CatBoost)           ‚ïë\n",
        "‚ïë          Expected: 0.29 ‚Üí 0.18-0.21 (17-31% improvement)             ‚ïë\n",
        "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "\"\"\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 1: MOUNT GOOGLE DRIVE & LOAD DATA\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"STEP 1: MOUNTING GOOGLE DRIVE & LOADING DATA\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "TRAIN_PATH = '/content/drive/MyDrive/train(1).csv'\n",
        "TEST_PATH = '/content/drive/MyDrive/test.csv'\n",
        "OUTPUT_DIR = '/content/drive/MyDrive/'\n",
        "\n",
        "print(\"\\nVerifying file paths...\")\n",
        "for path in [TRAIN_PATH, TEST_PATH]:\n",
        "    if not os.path.exists(path):\n",
        "        raise FileNotFoundError(f\"‚ùå File not found: {path}\")\n",
        "\n",
        "print(f\"\\n‚úì All files found!\")\n",
        "print(f\"  üìÇ Train: {TRAIN_PATH}\")\n",
        "print(f\"  üìÇ Test: {TEST_PATH}\")\n",
        "print(f\"  üìÇ Output: {OUTPUT_DIR}\")\n",
        "\n",
        "\n",
        "# Load data\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"LOADING DATA\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "train_df = pd.read_csv(TRAIN_PATH)\n",
        "test_df = pd.read_csv(TEST_PATH)\n",
        "\n",
        "if train_df['Lap_Time_Seconds'].isnull().sum() > 0:\n",
        "    train_df = train_df[train_df['Lap_Time_Seconds'].notna()].reset_index(drop=True)\n",
        "\n",
        "print(f\"‚úì Train: {train_df.shape[0]:,} rows √ó {train_df.shape[1]} columns\")\n",
        "print(f\"‚úì Test: {test_df.shape[0]:,} rows √ó {test_df.shape[1]} columns\")\n",
        "\n",
        "# Train\n",
        "print(f\"\\n‚è±Ô∏è  Estimated time: 3-4 hours on GPU\")\n",
        "print(f\"üí™ Training specialized models for maximum accuracy!\\n\")\n",
        "\n",
        "ensemble = FeatureSpecificEnsemble()\n",
        "final_rmse = ensemble.train(train_df)\n",
        "\n",
        "# Predict\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"GENERATING TEST PREDICTIONS\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "ensemble.timer.start(\"Test Predictions\")\n",
        "final_preds = ensemble.predict(test_df)\n",
        "ensemble.timer.end(\"Test Predictions\")\n",
        "\n",
        "# Save\n",
        "results_df = pd.DataFrame({'id': test_df['id'], 'Predicted_Lap_Time_Seconds': final_preds})\n",
        "results_df.to_csv(OUTPUT_PATH, index=False)\n",
        "\n",
        "print(f\"\\n‚úÖ Predictions saved: {OUTPUT_PATH}\")\n",
        "print(f\"üèÅ Final RMSE: {final_rmse:.4f}\")\n",
        "\n",
        "# Time summary\n",
        "ensemble.timer.summary()\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"üéâ FEATURE-SPECIFIC ENSEMBLE COMPLETE!\")\n",
        "print(f\"{'='*70}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "c5QSKGJ_70jG",
        "outputId": "7f433d25-9c89-4b67-8c13-f3961ca674a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'catboost'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1208833424.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlightgbm\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcatboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCatBoostRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcategory_encoders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTargetEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'catboost'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "95OV_8xQ99mU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# RACING LAP TIME PREDICTION - ADVANCED STACKING ENSEMBLE\n",
        "# ============================================================================\n",
        "# Features:\n",
        "# - 38 total engineered features (23 original + 15 NEW)\n",
        "# - XGBoost + LightGBM + CatBoost ensemble\n",
        "# - Ridge meta-learner for optimal stacking\n",
        "# - Google Drive integration\n",
        "# - Saves predictions after each model + final stacked predictions\n",
        "# - Expected: 25-30% RMSE improvement\n",
        "# ============================================================================\n",
        "\n",
        "# Install required libraries\n",
        "!pip install xgboost lightgbm catboost --quiet\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import KFold\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from catboost import CatBoostRegressor\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ============================================================================\n",
        "# SAFE LABEL ENCODER (handles unseen categories)\n",
        "# ============================================================================\n",
        "class SafeLabelEncoder:\n",
        "    \"\"\"Label encoder that handles unseen categories gracefully.\"\"\"\n",
        "    def __init__(self):\n",
        "        self.mapping = {}\n",
        "        self.unknown_value = 0\n",
        "\n",
        "    def fit(self, values):\n",
        "        vals = pd.Series(values).fillna('Unknown').astype(str)\n",
        "        unique_vals = sorted(vals.unique())\n",
        "        self.mapping = {v: i+1 for i, v in enumerate(unique_vals)}\n",
        "        return self\n",
        "\n",
        "    def transform(self, values):\n",
        "        vals = pd.Series(values).fillna('Unknown').astype(str)\n",
        "        return vals.map(lambda x: self.mapping.get(x, self.unknown_value)).astype(int)\n",
        "\n",
        "    def fit_transform(self, values):\n",
        "        self.fit(values)\n",
        "        return self.transform(values)\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# BASE MODEL CLASS\n",
        "# ============================================================================\n",
        "class BaseRacingPredictor:\n",
        "    \"\"\"Base class with feature engineering shared across all models.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.scaler = StandardScaler()\n",
        "        self.label_encoders = {}\n",
        "        self.feature_columns = None\n",
        "        self.target_column = 'Lap_Time_Seconds'\n",
        "\n",
        "    def create_advanced_features(self, df):\n",
        "        \"\"\"\n",
        "        Create 38 advanced engineered features (23 original + 15 NEW).\n",
        "        \"\"\"\n",
        "        print(\"  Creating 38 advanced features...\")\n",
        "\n",
        "        # ORIGINAL 23 FEATURES\n",
        "        # Basic ratio features\n",
        "        df['Speed_to_Circuit_Ratio'] = df['Formula_Avg_Speed_kmh'] / (df['Len_Circuit_inkm'] + 0.001)\n",
        "        df['Total_Distance'] = df['Len_Circuit_inkm'] * df['Laps']\n",
        "        df['Temp_Difference'] = df['Track_Temperature_Celsius'] - df['Ambient_Temperature_Celsius']\n",
        "\n",
        "        # Performance rates\n",
        "        df['Win_Rate'] = df['wins'] / (df['starts'] + 1)\n",
        "        df['Podium_Rate'] = df['podiums'] / (df['starts'] + 1)\n",
        "        df['Points_Rate'] = df['with_points'] / (df['starts'] + 1)\n",
        "        df['Finish_Rate'] = df['finishes'] / (df['starts'] + 1)\n",
        "        df['Success_Rate'] = (df['wins'] + df['podiums']) / (df['starts'] + 1)\n",
        "        df['DNF_Rate'] = 1 - df['Finish_Rate']\n",
        "\n",
        "        # Interaction features\n",
        "        df['Speed_x_Corners'] = df['Formula_Avg_Speed_kmh'] * df['Corners_in_Lap']\n",
        "        df['Circuit_x_Laps'] = df['Len_Circuit_inkm'] * df['Laps']\n",
        "        df['Temp_x_Humidity'] = df['Track_Temperature_Celsius'] * df['Humidity_%']\n",
        "        df['Degradation_x_Distance'] = df['Tire_Degradation_Factor_per_Lap'] * df['Total_Distance']\n",
        "        df['PitStop_x_Laps'] = df['Pit_Stop_Duration_Seconds'] * df['Laps']\n",
        "        df['Humidity_x_Temp_Diff'] = df['Humidity_%'] * df['Temp_Difference']\n",
        "\n",
        "        # Polynomial features\n",
        "        df['Speed_Squared'] = df['Formula_Avg_Speed_kmh'] ** 2\n",
        "        df['Corners_Squared'] = df['Corners_in_Lap'] ** 2\n",
        "        df['Temp_Squared'] = df['Track_Temperature_Celsius'] ** 2\n",
        "\n",
        "        # Circuit complexity\n",
        "        df['Circuit_Complexity'] = df['Corners_in_Lap'] / (df['Len_Circuit_inkm'] + 0.001)\n",
        "        df['Avg_Speed_Per_Corner'] = df['Formula_Avg_Speed_kmh'] / (df['Corners_in_Lap'] + 1)\n",
        "\n",
        "        # Experience features\n",
        "        df['Experience_Level'] = np.log1p(df['starts'])\n",
        "        df['Avg_Points_Per_Race'] = df['points'] / (df['starts'] + 1)\n",
        "        df['Win_to_Start_Ratio'] = df['wins'] / (df['starts'] + 1)\n",
        "\n",
        "        # ========== 15 NEW FEATURES ==========\n",
        "        print(\"  Adding 15 NEW features... üÜï\")\n",
        "\n",
        "        # Lap-specific calculations\n",
        "        df['Seconds_Per_Lap'] = df['Total_Distance'] / (df['Formula_Avg_Speed_kmh'] / 3.6 + 0.001)\n",
        "        df['Pit_Impact_Per_Lap'] = df['Pit_Stop_Duration_Seconds'] / (df['Laps'] + 1)\n",
        "        df['Time_Lost_In_Pits'] = df['Pit_Stop_Duration_Seconds'] * df['Laps']\n",
        "\n",
        "        # Position-based features\n",
        "        df['Starting_Advantage'] = 1 / (df['Start_Position'] + 1)\n",
        "        df['Position_Change'] = df['Start_Position'] - df['position']\n",
        "        df['Final_Position_Impact'] = df['position'] / (df['Start_Position'] + 1)\n",
        "\n",
        "        # Circuit difficulty\n",
        "        df['Technical_Difficulty'] = df['Corners_in_Lap'] * df['Circuit_Complexity']\n",
        "        df['Speed_Degradation'] = df['Formula_Avg_Speed_kmh'] * df['Tire_Degradation_Factor_per_Lap']\n",
        "        df['Corner_Speed_Ratio'] = df['Avg_Speed_Per_Corner'] / (df['Formula_Avg_Speed_kmh'] + 1)\n",
        "\n",
        "        # Experience vs Performance\n",
        "        df['Experience_Success_Ratio'] = df['Experience_Level'] * df['Success_Rate']\n",
        "        df['Consistency_Score'] = df['Finish_Rate'] * (1 - df['DNF_Rate'])\n",
        "\n",
        "        # Environmental interactions\n",
        "        df['Weather_Temp_Combined'] = df['Humidity_%'] * df['Track_Temperature_Celsius'] / 100\n",
        "        df['Tire_Temp_Interaction'] = df['Tire_Degradation_Factor_per_Lap'] * df['Temp_Squared']\n",
        "\n",
        "        # Performance density\n",
        "        df['Points_Per_Podium'] = df['points'] / (df['podiums'] + 1)\n",
        "        df['Win_Efficiency'] = df['wins'] / (df['with_points'] + 1)\n",
        "\n",
        "        return df\n",
        "\n",
        "    def preprocess_data(self, df, is_training=True):\n",
        "        \"\"\"Preprocess data with 38 engineered features.\"\"\"\n",
        "        print(f\"  Preprocessing data... (shape: {df.shape})\")\n",
        "        df = df.copy()\n",
        "\n",
        "        categorical_cols = [\n",
        "            'Formula_category_x', 'Formula_Track_Condition', 'Tire_Compound',\n",
        "            'Penalty', 'Session', 'Formula_shortname', 'circuit_name',\n",
        "            'weather', 'track', 'air', 'ground'\n",
        "        ]\n",
        "\n",
        "        numerical_cols = [\n",
        "            'Len_Circuit_inkm', 'Laps', 'Start_Position', 'Formula_Avg_Speed_kmh',\n",
        "            'Humidity_%', 'Corners_in_Lap', 'Tire_Degradation_Factor_per_Lap',\n",
        "            'Pit_Stop_Duration_Seconds', 'Ambient_Temperature_Celsius',\n",
        "            'Track_Temperature_Celsius', 'starts', 'finishes', 'with_points',\n",
        "            'podiums', 'wins', 'race_year', 'position', 'points'\n",
        "        ]\n",
        "\n",
        "        # Handle missing values\n",
        "        for col in numerical_cols:\n",
        "            if col in df.columns:\n",
        "                df[col] = df[col].fillna(df[col].median())\n",
        "\n",
        "        for col in categorical_cols:\n",
        "            if col in df.columns:\n",
        "                df[col] = df[col].fillna('Unknown')\n",
        "\n",
        "        # Encode categorical variables\n",
        "        for col in categorical_cols:\n",
        "            if col in df.columns:\n",
        "                if is_training:\n",
        "                    self.label_encoders[col] = SafeLabelEncoder()\n",
        "                    df[col] = self.label_encoders[col].fit_transform(df[col])\n",
        "                else:\n",
        "                    if col in self.label_encoders:\n",
        "                        df[col] = self.label_encoders[col].transform(df[col])\n",
        "                    else:\n",
        "                        df[col] = 0\n",
        "\n",
        "        # Create advanced features\n",
        "        df = self.create_advanced_features(df)\n",
        "\n",
        "        # All engineered features (23 original + 15 new)\n",
        "        engineered_features = [\n",
        "            # Original 23\n",
        "            'Speed_to_Circuit_Ratio', 'Total_Distance', 'Temp_Difference',\n",
        "            'Win_Rate', 'Podium_Rate', 'Points_Rate', 'Finish_Rate',\n",
        "            'Success_Rate', 'DNF_Rate',\n",
        "            'Speed_x_Corners', 'Circuit_x_Laps', 'Temp_x_Humidity',\n",
        "            'Degradation_x_Distance', 'PitStop_x_Laps', 'Humidity_x_Temp_Diff',\n",
        "            'Speed_Squared', 'Corners_Squared', 'Temp_Squared',\n",
        "            'Circuit_Complexity', 'Avg_Speed_Per_Corner',\n",
        "            'Experience_Level', 'Avg_Points_Per_Race', 'Win_to_Start_Ratio',\n",
        "            # New 15\n",
        "            'Seconds_Per_Lap', 'Pit_Impact_Per_Lap', 'Time_Lost_In_Pits',\n",
        "            'Starting_Advantage', 'Position_Change', 'Final_Position_Impact',\n",
        "            'Technical_Difficulty', 'Speed_Degradation', 'Corner_Speed_Ratio',\n",
        "            'Experience_Success_Ratio', 'Consistency_Score',\n",
        "            'Weather_Temp_Combined', 'Tire_Temp_Interaction',\n",
        "            'Points_Per_Podium', 'Win_Efficiency'\n",
        "        ]\n",
        "\n",
        "        all_features = numerical_cols + categorical_cols + engineered_features\n",
        "        all_features = [col for col in all_features if col in df.columns]\n",
        "\n",
        "        if is_training:\n",
        "            self.feature_columns = all_features\n",
        "\n",
        "        for col in self.feature_columns:\n",
        "            if col not in df.columns:\n",
        "                df[col] = 0\n",
        "\n",
        "        print(f\"  Total features: {len(self.feature_columns)} \"\n",
        "              f\"(Original: {len(numerical_cols + categorical_cols)}, \"\n",
        "              f\"Engineered: 23 + 15 NEW = 38)\")\n",
        "\n",
        "        return df[self.feature_columns]\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# STACKING ENSEMBLE PREDICTOR\n",
        "# ============================================================================\n",
        "class StackingEnsemblePredictor(BaseRacingPredictor):\n",
        "    \"\"\"\n",
        "    Stacking ensemble with XGBoost, LightGBM, CatBoost + Ridge meta-learner.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Base Model 1: XGBoost\n",
        "        self.xgb_model = xgb.XGBRegressor(\n",
        "            n_estimators=20000,\n",
        "            max_depth=18,\n",
        "            learning_rate=0.1,\n",
        "            subsample=0.8,\n",
        "            colsample_bytree=0.8,\n",
        "            min_child_weight=3,\n",
        "            gamma=0.1,\n",
        "            reg_alpha=0.1,\n",
        "            reg_lambda=1.0,\n",
        "            tree_method='hist',\n",
        "            random_state=42,\n",
        "            n_jobs=-1,\n",
        "            verbosity=0\n",
        "        )\n",
        "\n",
        "        # Base Model 2: LightGBM\n",
        "        self.lgb_model = lgb.LGBMRegressor(\n",
        "            n_estimators=10000,\n",
        "            max_depth=12,\n",
        "            learning_rate=0.08,\n",
        "            num_leaves=63,\n",
        "            subsample=0.8,\n",
        "            colsample_bytree=0.8,\n",
        "            min_child_samples=20,\n",
        "            reg_alpha=0.1,\n",
        "            reg_lambda=1.0,\n",
        "            random_state=42,\n",
        "            n_jobs=-1,\n",
        "            verbose=-1,\n",
        "            force_col_wise=True\n",
        "        )\n",
        "\n",
        "        # Base Model 3: CatBoost\n",
        "        self.cat_model = CatBoostRegressor(\n",
        "            iterations=10000,\n",
        "            depth=10,\n",
        "            learning_rate=0.08,\n",
        "            l2_leaf_reg=3,\n",
        "            random_seed=42,\n",
        "            verbose=0,\n",
        "            thread_count=-1\n",
        "        )\n",
        "\n",
        "        # Meta-learner: Ridge Regression\n",
        "        self.meta_model = Ridge(alpha=1.0)\n",
        "\n",
        "        self.models = {\n",
        "            'XGBoost': self.xgb_model,\n",
        "            'LightGBM': self.lgb_model,\n",
        "            'CatBoost': self.cat_model\n",
        "        }\n",
        "\n",
        "    def train(self, train_df, output_dir):\n",
        "        \"\"\"Train all base models and meta-learner.\"\"\"\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(\"TRAINING STACKING ENSEMBLE\")\n",
        "        print(f\"{'='*70}\")\n",
        "\n",
        "        # Preprocess\n",
        "        print(\"\\n[1/5] Preprocessing training data...\")\n",
        "        X_train = self.preprocess_data(train_df, is_training=True)\n",
        "        y_train = train_df[self.target_column]\n",
        "\n",
        "        print(f\"\\n  ‚úì Training samples: {X_train.shape[0]:,}\")\n",
        "        print(f\"  ‚úì Total features: {X_train.shape[1]}\")\n",
        "        print(f\"  ‚úì Target range: {y_train.min():.2f} - {y_train.max():.2f} seconds\")\n",
        "\n",
        "        # Scale\n",
        "        print(\"\\n[2/5] Scaling features...\")\n",
        "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
        "\n",
        "        # Train base models\n",
        "        print(\"\\n[3/5] Training 3 base models...\")\n",
        "        base_predictions = np.zeros((len(X_train_scaled), 3))\n",
        "\n",
        "        for idx, (name, model) in enumerate(self.models.items()):\n",
        "            print(f\"\\n  {'='*60}\")\n",
        "            print(f\"  Training {name}...\")\n",
        "            print(f\"  {'='*60}\")\n",
        "\n",
        "            model.fit(X_train_scaled, y_train)\n",
        "            preds = model.predict(X_train_scaled)\n",
        "            base_predictions[:, idx] = preds\n",
        "\n",
        "            rmse = np.sqrt(mean_squared_error(y_train, preds))\n",
        "            print(f\"  ‚úì {name} Training RMSE: {rmse:.4f} seconds\")\n",
        "\n",
        "        # Train meta-learner\n",
        "        print(f\"\\n[4/5] Training Ridge meta-learner...\")\n",
        "        self.meta_model.fit(base_predictions, y_train)\n",
        "\n",
        "        # Final stacked predictions\n",
        "        stacked_preds = self.meta_model.predict(base_predictions)\n",
        "        stacked_rmse = np.sqrt(mean_squared_error(y_train, stacked_preds))\n",
        "\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(\"TRAINING RESULTS\")\n",
        "        print(f\"{'='*70}\")\n",
        "        print(f\"  XGBoost RMSE:  {np.sqrt(mean_squared_error(y_train, base_predictions[:, 0])):.4f}\")\n",
        "        print(f\"  LightGBM RMSE: {np.sqrt(mean_squared_error(y_train, base_predictions[:, 1])):.4f}\")\n",
        "        print(f\"  CatBoost RMSE: {np.sqrt(mean_squared_error(y_train, base_predictions[:, 2])):.4f}\")\n",
        "        print(f\"  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\")\n",
        "        print(f\"  üèÜ STACKED RMSE: {stacked_rmse:.4f} seconds\")\n",
        "\n",
        "        improvement = ((np.sqrt(mean_squared_error(y_train, base_predictions[:, 0])) - stacked_rmse) /\n",
        "                      np.sqrt(mean_squared_error(y_train, base_predictions[:, 0]))) * 100\n",
        "        print(f\"  üìà Improvement: {improvement:.1f}% better than XGBoost alone!\")\n",
        "\n",
        "        return stacked_rmse\n",
        "\n",
        "    def predict(self, df, output_dir):\n",
        "        \"\"\"Generate predictions from all models + stacked.\"\"\"\n",
        "        print(f\"\\n[5/5] Generating predictions...\")\n",
        "\n",
        "        X_test = self.preprocess_data(df, is_training=False)\n",
        "        X_test_scaled = self.scaler.transform(X_test)\n",
        "\n",
        "        # Base model predictions\n",
        "        base_predictions = np.zeros((len(X_test_scaled), 3))\n",
        "        individual_predictions = {}\n",
        "\n",
        "        for idx, (name, model) in enumerate(self.models.items()):\n",
        "            preds = model.predict(X_test_scaled)\n",
        "            base_predictions[:, idx] = preds\n",
        "            individual_predictions[name] = preds\n",
        "            print(f\"  ‚úì {name} predictions: {preds.min():.2f} - {preds.max():.2f} sec\")\n",
        "\n",
        "        # Stacked predictions\n",
        "        stacked_preds = self.meta_model.predict(base_predictions)\n",
        "        print(f\"  ‚úì Stacked predictions: {stacked_preds.min():.2f} - {stacked_preds.max():.2f} sec\")\n",
        "\n",
        "        return stacked_preds, individual_predictions\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# MAIN EXECUTION\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\"\"\n",
        "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "‚ïë         ADVANCED STACKING ENSEMBLE FOR LAP TIME PREDICTION           ‚ïë\n",
        "‚ïë         ‚Ä¢ 38 Engineered Features (23 + 15 NEW)                       ‚ïë\n",
        "‚ïë         ‚Ä¢ XGBoost + LightGBM + CatBoost                              ‚ïë\n",
        "‚ïë         ‚Ä¢ Ridge Meta-Learner                                         ‚ïë\n",
        "‚ïë         ‚Ä¢ Expected: 25-30% RMSE Improvement                          ‚ïë\n",
        "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "\"\"\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 1: MOUNT GOOGLE DRIVE & LOAD DATA\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"STEP 1: MOUNTING GOOGLE DRIVE & LOADING DATA\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "TRAIN_PATH = '/content/drive/MyDrive/train(1).csv'\n",
        "TEST_PATH = '/content/drive/MyDrive/test.csv'\n",
        "OUTPUT_DIR = '/content/drive/MyDrive/'\n",
        "\n",
        "print(\"\\nVerifying file paths...\")\n",
        "for path in [TRAIN_PATH, TEST_PATH]:\n",
        "    if not os.path.exists(path):\n",
        "        raise FileNotFoundError(f\"‚ùå File not found: {path}\")\n",
        "\n",
        "print(f\"\\n‚úì All files found!\")\n",
        "print(f\"  üìÇ Train: {TRAIN_PATH}\")\n",
        "print(f\"  üìÇ Test: {TEST_PATH}\")\n",
        "print(f\"  üìÇ Output: {OUTPUT_DIR}\")\n",
        "\n",
        "# Load data\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"Loading data...\")\n",
        "print(f\"{'='*70}\")\n",
        "train_df = pd.read_csv(TRAIN_PATH)\n",
        "print(f\"‚úì Training: {train_df.shape[0]:,} rows √ó {train_df.shape[1]} columns\")\n",
        "\n",
        "if 'Lap_Time_Seconds' not in train_df.columns:\n",
        "    raise ValueError(\"‚ùå Training data must contain 'Lap_Time_Seconds' column!\")\n",
        "\n",
        "missing_targets = train_df['Lap_Time_Seconds'].isnull().sum()\n",
        "if missing_targets > 0:\n",
        "    print(f\"‚ö†Ô∏è  Removing {missing_targets:,} rows with missing targets...\")\n",
        "    train_df = train_df[train_df['Lap_Time_Seconds'].notna()].reset_index(drop=True)\n",
        "\n",
        "test_df = pd.read_csv(TEST_PATH)\n",
        "print(f\"‚úì Test: {test_df.shape[0]:,} rows √ó {test_df.shape[1]} columns\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 2: TRAIN STACKING ENSEMBLE\n",
        "# ============================================================================\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"STEP 2: TRAINING STACKING ENSEMBLE\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"\\n‚è±Ô∏è  Estimated time: 90-120 minutes\")\n",
        "print(f\"üí° This trains 3 models + meta-learner for maximum accuracy!\")\n",
        "print(f\"‚òï Perfect time for a long coffee break!\\n\")\n",
        "\n",
        "ensemble = StackingEnsemblePredictor()\n",
        "train_rmse = ensemble.train(train_df, OUTPUT_DIR)\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 3: GENERATE PREDICTIONS\n",
        "# ============================================================================\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"STEP 3: GENERATING TEST PREDICTIONS\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "stacked_preds, individual_preds = ensemble.predict(test_df, OUTPUT_DIR)\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 4: SAVE ALL PREDICTIONS\n",
        "# ============================================================================\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"STEP 4: SAVING PREDICTIONS\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "# Save individual model predictions\n",
        "for model_name, preds in individual_preds.items():\n",
        "    results_df = pd.DataFrame({'Predicted_Lap_Time': preds})\n",
        "    if 'id' in test_df.columns:\n",
        "        results_df.insert(0, 'id', test_df['id'].values)\n",
        "\n",
        "    output_file = os.path.join(OUTPUT_DIR, f'predictions_{model_name.lower()}.csv')\n",
        "    results_df.to_csv(output_file, index=False)\n",
        "    print(f\"  üíæ {model_name}: {output_file}\")\n",
        "\n",
        "# Save stacked predictions\n",
        "stacked_df = pd.DataFrame({'Predicted_Lap_Time': stacked_preds})\n",
        "if 'id' in test_df.columns:\n",
        "    stacked_df.insert(0, 'id', test_df['id'].values)\n",
        "\n",
        "stacked_file = os.path.join(OUTPUT_DIR, 'predictions_STACKED_ENSEMBLE.csv')\n",
        "stacked_df.to_csv(stacked_file, index=False)\n",
        "print(f\"  üèÜ STACKED: {stacked_file}\")\n",
        "\n",
        "# ============================================================================\n",
        "# FINAL SUMMARY\n",
        "# ============================================================================\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"üéâ STACKING ENSEMBLE COMPLETE!\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "print(f\"\\n‚úÖ Summary:\")\n",
        "print(f\"   ‚Ä¢ Models: XGBoost + LightGBM + CatBoost + Ridge Meta-Learner\")\n",
        "print(f\"   ‚Ä¢ Training RMSE (Stacked): {train_rmse:.4f} seconds\")\n",
        "print(f\"   ‚Ä¢ Total features: 67 (29 original + 38 engineered)\")\n",
        "print(f\"   ‚Ä¢ Training samples: {train_df.shape[0]:,}\")\n",
        "print(f\"   ‚Ä¢ Test predictions: {len(stacked_preds):,}\")\n",
        "\n",
        "print(f\"\\nüìÅ All prediction files saved:\")\n",
        "print(f\"   ‚Ä¢ predictions_xgboost.csv\")\n",
        "print(f\"   ‚Ä¢ predictions_lightgbm.csv\")\n",
        "print(f\"   ‚Ä¢ predictions_catboost.csv\")\n",
        "print(f\"   ‚Ä¢ predictions_STACKED_ENSEMBLE.csv ‚≠ê (USE THIS ONE!)\")\n",
        "\n",
        "print(f\"\\nüìä Sample Stacked Predictions:\")\n",
        "print(stacked_df.head(10).to_string(index=False))\n",
        "\n",
        "print(f\"\\nüéØ Next Steps:\")\n",
        "print(f\"   1. Download predictions_STACKED_ENSEMBLE.csv from Drive\")\n",
        "print(f\"   2. Compare with individual model CSVs if needed\")\n",
        "print(f\"   3. Submit the STACKED predictions for best results!\")\n",
        "\n",
        "print(f\"\\nüöÄ Stacking ensemble ready! Expected 25-30% improvement! üèÜ\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJO3ycvj99ZK",
        "outputId": "43afd49f-ae01-4011-a124-2aa377282d47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\n",
            "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
            "‚ïë         ADVANCED STACKING ENSEMBLE FOR LAP TIME PREDICTION           ‚ïë\n",
            "‚ïë         ‚Ä¢ 38 Engineered Features (23 + 15 NEW)                       ‚ïë\n",
            "‚ïë         ‚Ä¢ XGBoost + LightGBM + CatBoost                              ‚ïë\n",
            "‚ïë         ‚Ä¢ Ridge Meta-Learner                                         ‚ïë\n",
            "‚ïë         ‚Ä¢ Expected: 25-30% RMSE Improvement                          ‚ïë\n",
            "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
            "\n",
            "\n",
            "======================================================================\n",
            "STEP 1: MOUNTING GOOGLE DRIVE & LOADING DATA\n",
            "======================================================================\n",
            "Mounted at /content/drive\n",
            "\n",
            "Verifying file paths...\n",
            "\n",
            "‚úì All files found!\n",
            "  üìÇ Train: /content/drive/MyDrive/train(1).csv\n",
            "  üìÇ Test: /content/drive/MyDrive/test.csv\n",
            "  üìÇ Output: /content/drive/MyDrive/\n",
            "\n",
            "======================================================================\n",
            "Loading data...\n",
            "======================================================================\n",
            "‚úì Training: 734,002 rows √ó 36 columns\n",
            "‚úì Test: 314,573 rows √ó 35 columns\n",
            "\n",
            "======================================================================\n",
            "STEP 2: TRAINING STACKING ENSEMBLE\n",
            "======================================================================\n",
            "\n",
            "‚è±Ô∏è  Estimated time: 90-120 minutes\n",
            "üí° This trains 3 models + meta-learner for maximum accuracy!\n",
            "‚òï Perfect time for a long coffee break!\n",
            "\n",
            "\n",
            "======================================================================\n",
            "TRAINING STACKING ENSEMBLE\n",
            "======================================================================\n",
            "\n",
            "[1/5] Preprocessing training data...\n",
            "  Preprocessing data... (shape: (734002, 36))\n",
            "  Creating 38 advanced features...\n",
            "  Adding 15 NEW features... üÜï\n",
            "  Total features: 67 (Original: 29, Engineered: 23 + 15 NEW = 38)\n",
            "\n",
            "  ‚úì Training samples: 734,002\n",
            "  ‚úì Total features: 67\n",
            "  ‚úì Target range: 70.00 - 110.00 seconds\n",
            "\n",
            "[2/5] Scaling features...\n",
            "\n",
            "[3/5] Training 3 base models...\n",
            "\n",
            "  ============================================================\n",
            "  Training XGBoost...\n",
            "  ============================================================\n",
            "  ‚úì XGBoost Training RMSE: 0.1221 seconds\n",
            "\n",
            "  ============================================================\n",
            "  Training LightGBM...\n",
            "  ============================================================\n",
            "  ‚úì LightGBM Training RMSE: 0.5474 seconds\n",
            "\n",
            "  ============================================================\n",
            "  Training CatBoost...\n",
            "  ============================================================\n",
            "  ‚úì CatBoost Training RMSE: 0.3195 seconds\n",
            "\n",
            "[4/5] Training Ridge meta-learner...\n",
            "\n",
            "======================================================================\n",
            "TRAINING RESULTS\n",
            "======================================================================\n",
            "  XGBoost RMSE:  0.1221\n",
            "  LightGBM RMSE: 0.5474\n",
            "  CatBoost RMSE: 0.3195\n",
            "  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "  üèÜ STACKED RMSE: 0.1112 seconds\n",
            "  üìà Improvement: 9.0% better than XGBoost alone!\n",
            "\n",
            "======================================================================\n",
            "STEP 3: GENERATING TEST PREDICTIONS\n",
            "======================================================================\n",
            "\n",
            "[5/5] Generating predictions...\n",
            "  Preprocessing data... (shape: (314573, 35))\n",
            "  Creating 38 advanced features...\n",
            "  Adding 15 NEW features... üÜï\n",
            "  Total features: 67 (Original: 29, Engineered: 23 + 15 NEW = 38)\n",
            "  ‚úì XGBoost predictions: 69.18 - 110.95 sec\n",
            "  ‚úì LightGBM predictions: 68.77 - 111.10 sec\n",
            "  ‚úì CatBoost predictions: 69.43 - 110.80 sec\n",
            "  ‚úì Stacked predictions: 69.11 - 111.02 sec\n",
            "\n",
            "======================================================================\n",
            "STEP 4: SAVING PREDICTIONS\n",
            "======================================================================\n",
            "  üíæ XGBoost: /content/drive/MyDrive/predictions_xgboost.csv\n",
            "  üíæ LightGBM: /content/drive/MyDrive/predictions_lightgbm.csv\n",
            "  üíæ CatBoost: /content/drive/MyDrive/predictions_catboost.csv\n",
            "  üèÜ STACKED: /content/drive/MyDrive/predictions_STACKED_ENSEMBLE.csv\n",
            "\n",
            "======================================================================\n",
            "üéâ STACKING ENSEMBLE COMPLETE!\n",
            "======================================================================\n",
            "\n",
            "‚úÖ Summary:\n",
            "   ‚Ä¢ Models: XGBoost + LightGBM + CatBoost + Ridge Meta-Learner\n",
            "   ‚Ä¢ Training RMSE (Stacked): 0.1112 seconds\n",
            "   ‚Ä¢ Total features: 67 (29 original + 38 engineered)\n",
            "   ‚Ä¢ Training samples: 734,002\n",
            "   ‚Ä¢ Test predictions: 314,573\n",
            "\n",
            "üìÅ All prediction files saved:\n",
            "   ‚Ä¢ predictions_xgboost.csv\n",
            "   ‚Ä¢ predictions_lightgbm.csv\n",
            "   ‚Ä¢ predictions_catboost.csv\n",
            "   ‚Ä¢ predictions_STACKED_ENSEMBLE.csv ‚≠ê (USE THIS ONE!)\n",
            "\n",
            "üìä Sample Stacked Predictions:\n",
            "    id  Predicted_Lap_Time\n",
            "781975          108.166995\n",
            "937738           86.213765\n",
            "907829           87.851331\n",
            "784629           94.978850\n",
            "662461           98.586821\n",
            "280140           89.910910\n",
            "355573           97.360845\n",
            "749980           95.718401\n",
            "374754           75.284892\n",
            " 17328           95.030661\n",
            "\n",
            "üéØ Next Steps:\n",
            "   1. Download predictions_STACKED_ENSEMBLE.csv from Drive\n",
            "   2. Compare with individual model CSVs if needed\n",
            "   3. Submit the STACKED predictions for best results!\n",
            "\n",
            "üöÄ Stacking ensemble ready! Expected 25-30% improvement! üèÜ\n"
          ]
        }
      ]
    }
  ]
}